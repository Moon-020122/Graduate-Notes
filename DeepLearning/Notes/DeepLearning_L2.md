# 训练、开发、测试集

1. **训练集 (Training Set)**:

   - **作用**：训练集用于训练机器学习模型。模型通过观察训练集中的样本来学习数据的模式、特征和关系。
   - **示例**：假设构建一个垃圾邮件分类器。训练集将包含已标记为“垃圾邮件”或“非垃圾邮件”的电子邮件样本。模型将使用这些样本来学习如何区分垃圾邮件和非垃圾邮件。

2. **验证集 (Validation Set)**:

   - **作用**：验证集用于调整模型的超参数（例如学习率、正则化参数等）。它帮助我们选择最佳的模型配置，以避免过拟合或欠拟合。
   - **示例**：在训练过程中，使用验证集来评估不同超参数设置的性能。例如，可以尝试不同的隐藏层大小、学习率等，并选择在验证集上表现最好的模型。

3. **测试集 (Test Set)**:

   - **作用**：测试集用于评估模型的泛化能力。是模型在未见过的数据上的性能指标。

   - **示例**：在训练和验证之后，使用测试集来评估模型的准确性、召回率、精确度等指标。测试集中的样本与训练集和验证集中的样本不重复，以确保模型在新数据上的表现。

# 偏差、方差

对于下方照片，第一个是高偏差的情况，中间为适度拟合，右边为高度拟合。![image-20240605200531746](images/image-20240605200531746.png)

理解偏差和方差的两个关键数据是训练集误差和验证集误差。

**高方差：**即高度拟合，训练集效果好，验证集效果差，如训练集的误差为1%而验证集的误差为11%。

**高偏差：**即训练集的错误率高，也即欠拟合，和验证集的结果却较为合理。如训练集的误差为15%而验证集的误差为16%。

**高偏差且高方差：**即训练集的错误率高的同时，验证集的结果也不合理。如训练集的误差为15%而验证集的误差为30%。

如训练集的误差为0.5%，验证集的误差为1%，则是低偏差低方差，为模型优秀结果。

**最优误差(基本误差)：**如果假设人类的识别程度的错误率为15%，那么验证集的错误率15%也为合理情况。

如果出现高偏差的情况无法拟合训练集，则选择新的网络；如果偏差适合的情况下，方差高则最好的解决办法就是采用更多数据或者正则化来减少拟合。

## 2.1-正则化

​	一般用于高方差的情况下；**正则化**（Regularization）：用于控制模型的复杂度，防止模型在训练数据上过度拟合（overfitting）。当模型过度拟合时，它会学习到训练数据中的噪声和细微变化，导致在新数据上的性能下降。

![image-20240605205134599](images/image-20240605205134599.png)

**L1 正则化**:

- **数学形式**

  : L1 正则化通过在损失函数中添加权重参数的绝对值之和作为惩罚项。这可以表示为损失函数 ![image-20240605205320014](images/image-20240605205320014.png)加上正则化项![image-20240605205344967](images/image-20240605205344967.png)

  **效果**: L1 正则化倾向于产生稀疏的权重矩阵，即许多权重会变为零。这意味着它可以用于特征选择，因为它会自动去除不重要的特征（权重为零的特征）。
  
  **L1范数**（也称为曼哈顿距离）：
  
  - **定义**：L1范数是向量中各个元素绝对值之和。
  - **作用**：L1范数倾向于产生稀疏的权重矩阵，即许多权重会变为零。因此，它可以用于特征选择。
  - **示例**：在对用户的电影爱好进行分类时，L1范数可以过滤掉无用的特征，只保留对分类有用的特征

**L2 正则化**（权重衰减）:

- **数学形式**:

   L2 正则化通过在损失函数中添加权重参数的平方和作为惩罚项。这可以表示为损失函数![image-20240605205320014](images/image-20240605205320014.png)加上正则化项![image-20240605205523676](images/image-20240605205523676.png)

  **效果**: L2 正则化会使权重值变得较小，但不会将它们推向零，这意味着它不会产生稀疏模型。L2 正则化有助于控制模型的复杂度，但不具备特征选择的功能。

  **L2范数**（弗罗贝尼乌斯范数）（也称为欧氏距离）：

  - **定义**：L2范数是向量元素平方和再开平方。
  - **作用**：L2范数不会将权重推向零，但会使权重变得较小，从而防止过拟合。
  - **示例**：在模型优化中，L2范数通常用作正则化项，以提高模型的泛化能力。

![image-20240605214643543](images/image-20240605214643543.png)

​	当λ足够大时，它会对权重矩阵施加很大的惩罚，导致权重的值减小，甚至趋于0。神经网络会越来越接近逻辑回归，但神经网络的隐藏单元依旧存在，只不过影响变小了。

​	损失函数中加入L2正则化项时，算法会尝试最小化损失函数和正则化项的总和（成本函数）。由于正则化项是权重的平方和，增加λ会使得优化算法在减少损失的同时，也倾向于将权重值减小，以降低正则化项的值。如果λ设置得非常大，那么优化算法在减少正则化项的过程中，会将权重推向。

​	当权重值减小或趋于0时，隐藏单元与输入和输出之间的连接变得非常弱。意味着隐藏单元对模型的输出贡献减少，从而减少了它们的影响力。虽然隐藏单元仍然存在，但对最终结果的影响也会变得很小，使得整个网络的行为更像是一个简单的逻辑回归分类器。

![image-20240607122958629](images/image-20240607122958629.png)

### **为什么正则化可以减少过拟合？**

​	即正则化通过添加一个与权重相关的惩罚项到损失函数中，鼓励模型学习更小的权重，而这样会使得模型倾向于学习更简单的、泛化能力更强的模式，而不是复杂的模式，这些复杂的模式可能只在训练数据上有效，但在未见过的数据上则不一定有效（过拟合）。

​	以tanh激活函数为例，当正则化参数λ增大，导致权重w减小，因为z是输入x和权重w的线性组合，所以z的值也会减小。当z的值较小时，tanh函数的输出接近线性关系（因为tanh函数在原点附近是近似线性的，如图所示）。这意味着，随着λ的增加，神经网络的非线性效应减弱，模型的复杂度降低，从而减少了过拟合的风险。

tanh函数可以表示为：
$$
\text{tanh}(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}}
$$
当z的值较小（即接近0）时，tanh函数可以近似为：
$$
\text{tanh}(z) \approx z
$$
![image-20240607123827795](images/image-20240607123827795.png)

## 2.2-dropout(随机失活)正则化

dropout会遍历网络的每一层，并设置消除神经网络中节点的概率，假设我们设置每一层的消除概率为0.5，即理论上有一半的隐藏单元会被消除，那么这个消除后的神经网络既是正则化后的神经网络。

​	通过在训练过程中随机地丢弃（即将权重设置为0）网络中的一部分神经元来减少过拟合。在每一层设置一个丢弃概率。如0.5，则在每次训练迭代中，每个神经元都有50%的概率不被包括在前向和后向传播中。这样，网络的每次训练迭代都是在一种略微不同的网络架构下完成的。

​	这种方法的效果类似于训练多个不同的网络，并将它们的预测结果进行平均。因为每次迭代都随机丢弃不同的神经元，所以实际上是在训练多个“子网络”。这些子网络共享权重，因此dropout可以被看作是一种非常高效的模型集成方法。

![image-20240607130819065](images/image-20240607130819065.png)

### inverted dropout（反向随机失活）

​	keep-prob是一个概率，意味为1的概率是多少，此处为0.8即80%为1，20%为0，后将a3(第三层输出)与d3相乘，然后将a3中对应于d3中为0的位置置1，也即是完成了消除。

​	在使用dropout正则化时，除以keep-prob（保留概率）是为了保证激活值的期望不变。在dropout过程中，一部分神经元会被随机丢弃，从而减少了网络的有效容量。如果不进行调整，那么在训练阶段，神经元的输出激活值的期望会因为dropout而减少。

​	例如，假设keep-prob为0.8，这意味着有20%的神经元会被丢弃。剩下的神经元的输出激活值的总和将只有原来的80%，这会影响到后续层的学习过程。我们需要将激活值除以keep-prob，这样在期望上，激活值的总和仍然保持不变。假设一个神经元的输出激活值为 ( a )，在不使用dropout的情况下，其期望值为 ( a )。如果使用了dropout，神经元的输出激活值的期望变为 ：
$$
\text{keep-prob} \times a
$$
​	为了使期望值与不使用dropout时一致，我们需要将激活值除以keep-prob，即：
$$
\frac{\text{keep-prob} \times a}{\text{keep-prob}} = a
$$
![image-20240607132538222](images/image-20240607132538222.png)

​	而在测试阶段不用使用dropout。其原因是，我们希望模型能够利用其全部学到的知识来进行预测，而不是依赖于训练时的随机性。Dropout是一种正则化技术，它通过在训练过程中随机地关闭一部分神经元来防止模型过拟合。这种随机性有助于模型学习到更加鲁棒（鲁棒性（Robustness）指的是系统在面对各种变化、干扰或不确定性时，仍能保持正常运行和正确输出结果的能力。）的特征表示，因为它不能依赖于任何特定的神经元激活模式。

​	在测试阶段，我们需要模型给出稳定的预测结果。如果在测试时也使用dropout，那么每次运行模型时都可能得到不同的结果，因为不同的神经元会被随机关闭。这会导致模型的预测性能下降，因为我们无法保证模型每次都能使用最佳的神经元组合来做出决策。由于在训练阶段使用了dropout，模型的权重已经适应了在一定比例的神经元被关闭的情况下进行预测。因此，在测试阶段，我们可以使用所有的神经元（即不使用dropout），但权重可能会乘以保留概率（keep-prob），以保持激活值的总和与训练阶段相似。这样做可以确保模型的输出反映了训练时学到的所有知识，同时保持了预测的一致性。

### 理解dropout

​	Dropout作为一种正则化技术，会随机地关闭网络中的一些单元，这样做的目的是为了防止网络对于训练数据的过度拟合。当一个单元被关闭时，它在当前训练迭代中不会对前向传播和反向传播产生影响。这迫使网络不会对任何一个输入特征赋予过多的权重，因为在训练过程中，这些特征可能会被随机删除。因此，网络必须学习更加分散的权重，以便在某些输入特征缺失时仍能做出准确的预测。

​	Dropout的效果类似于L2正则化，因为它倾向于减小权重的大小，但它们的工作原理有所不同。L2正则化通过惩罚权重的平方和来工作，导致所有权重都均匀地缩小，特别是对于那些较大的权重。而Dropout则是通过随机地关闭单元来实现正则化，这种方法不是均匀地缩小权重，而是增加了权重配置的多样性。

​	对于不同层应用不同的keep-prob（保留概率），因为不同的层可能对过拟合的敏感度不同。例如，如果某个权重矩阵特别大，可能需要更高的dropout率来防止过拟合；而对于那些我们认为不太可能过拟合的层，可以设置较高的keep-prob，甚至可以是1，意味着这些层不使用dropout。

​	Dropout主要用于计算机视觉领域，在这个领域中，模型往往非常深且复杂，容易过拟合。在其他类型的问题中，可能不需要使用dropout，或者使用其他形式的正则化就足够了。这取决于具体问题的复杂性、数据的数量和质量，以及模型的结构。

![image-20240607150642455](images/image-20240607150642455.png)

## 2.3-其他正则化的方法

通过改变图片的方式来伪增加图片集。![image-20240607151407146](images/image-20240607151407146.png)

#### Early stopping

​	Early stopping是一种防止神经网络过拟合的正则化技术。它的基本思想是在训练过程中，当模型在验证集上的性能不再提升时停止训练。这样做的目的是为了避免权重w变得过大，从而导致模型在训练数据上过度拟合。

​	在神经网络的训练过程中，权重w通常是从较小的随机值开始的。随着训练的进行，权重w会逐渐增大，以最小化训练集上的损失函数。如果训练时间过长，权重w可能会变得非常大，这时模型可能会开始学习训练数据中的噪声，而不是潜在的、更一般的模式，即过拟合现象。

Early stopping通过在验证集上监控性能来解决这个问题。当连续多个epoch性能没有提升时，就会停止训练。这通常意味着模型在验证集上的误差开始增加，表明模型可能开始过拟合。通过在这个“中间点”停止训练，我们可以得到一个大小适中的权重w，有助于保持模型的泛化能力，同时避免过拟合。

![image-20240607153026046](images/image-20240607153026046.png)

# 归一化输入

​	归一化输入数据是一个重要的预处理步骤，有助于算法更快地收敛并提高模型的性能。这个过程通常包括两个步骤：零均值化和方差归一化。

​	**第一步：零均值化** ，也称为中心化，指将输入变量的均值变为零。对于每个特征，我们从该特征的所有数据点中减去其平均值。数学上，如果我们有一个特征 ( X )，其均值为μ，零均值化后的特征 ( X’ ) 计算如下：
$$
\mu = \frac{1}{n}\sum_{i=1}^{n}x_i
$$

$$
X' = X - \mu
$$

​	将数据集的中心移至原点。在优化过程中，这有助于梯度下降等算法更快地找到最小值，它确保了所有特征都在同一尺度上被考虑，避免了某些特征由于数值范围大而对结果产生不成比例的影响。

​	**第二步：方差归一化** ，也称为标准化，是指将输入变量的方差变为1，当方差变为1时，这意味着数据的分布具有单位方差，也就是说，数据点在数值上相对于均值的平均距离是标准化的。这种情况下，数据的分布被称为“标准化”或“单位化”。通过将特征值除以其标准差来实现的，设特征 ( X’ ) 的标准差为 ( σ )。

​	标准差是衡量数据点偏离均值的程度的指标。首先，我们需要计算每个数据点与均值之差的平方，然后求和，最后除以数据点的数量（对于样本标准差，除以 ( n-1 )），再取平方根。标准差 (σ  ) 计算如下
$$
\sigma = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(x_i - \mu)^2} 
$$
​	则归一化后的特征 ( X’’ ) 计算如下：
$$
X'' = \frac{X'}{\sigma}
$$
​	确保了所有特征具有相同的尺度，这意味着它们对模型的贡献是平等的。例如，在使用基于距离的算法（如K-最近邻或支持向量机）时，未归一化的特征可能会由于其值的范围较大而对距离计算产生过大影响。

​	**Eg:**假设我们有两个特征，一个是人的身高（以厘米为单位），另一个是体重（以千克为单位）。身高的范围可能是150到200厘米，而体重的范围可能是50到100千克。如果直接使用这些原始数据进行机器学习，体重特征因为数值范围更大，可能会对模型产生更大的影响。但通过将这两个特征的方差都标准化为1，我们确保了它们在模型中的影响是平等的，从而使模型更加公正和有效。

![image-20240608125154838](images/image-20240608125154838.png)

## 3.1-基本原理

![image-20240608130703055](images/image-20240608130703055.png)	

​	如果使用非归一化的输入特征，代价函数会如左图所示，这是一个非常细长狭窄的成本函数；如果使用归一化，代价函数平均起来看更对称。

​	代价函数的形状会受到特征值范围的影响。如果特征 ( X_1 ) 的取值范围是 ( (0, 1000) )，而 ( X_2 ) 的取值范围是 ( (0, 1) )，那么 ( X_1 ) 在代价函数中的影响会远大于 ( X_2 )。这是因为 ( X_1 ) 的变化对代价函数的影响更大，即使它的变化很小。

​	这会导致代价函数的等高线（代价相同的点的集合）变得非常细长和狭窄，类似于左图所示。在这种情况下，梯度下降算法在不同方向上前进的速度差异很大：沿着 ( X_1 ) 方向的梯度会非常大，而沿着 ( X_2 ) 方向的梯度会非常小。因此，为了避免在 ( X_1 ) 方向上的大步长导致梯度下降超过最小值，我们需要使用一个非常小的学习率。

​	如果我们对输入特征进行归一化，使得所有特征的取值范围相似，那么代价函数的等高线会更加对称，类似于右图所示。这样，梯度下降算法在所有方向上前进的速度会更加均匀，可以使用更大的学习率，而不会有超过最小值的风险。这也意味着梯度下降算法可以更快地收敛到最小值。![image-20240608131257821](images/image-20240608131257821.png)

# 梯度消失和梯度爆炸

​	梯度爆炸或梯度消失：当训练神经网络时，导数或梯度的变化非常大或非常小，甚至以指数方式变小的现象。

​	**激活函数饱和**：使用像sigmoid或tanh这样的激活函数时，当输入值非常大或非常小，激活函数的导数接近于零，这会导致梯度消失。
​	**权重初始化**：如果权重初始化得太大，那么在网络的前向传播过程中，激活函数的输出可能会变得非常大，导致梯度在反向传播时爆炸。相反，如果权重初始化得太小，激活函数的输出可能会变得非常小，导致梯度消失。
​	**深层网络结构**：在深层网络中，梯度必须通过多个层进行反向传播。如果每层的梯度都小于1，那么最终的梯度会随着层数的增加而指数级减小，导致梯度消失。同样，如果每层的梯度都大于1，那么梯度会随着层数的增加而指数级增大，导致梯度爆炸。

![image-20240608235311723](images/image-20240608235311723.png)

## 4.1-权重初始化

​	方差衡量的是数据分布的离散程度，即数据值与其平均值的偏离程度。在神经网络中，权重的方差决定了通过该层传播的信号的分散程度。如果方差太大，信号可能会随着层数的增加而放大，导致梯度爆炸；如果方差太小，信号可能会逐渐衰减，导致梯度消失。

​	**独立同分布的方差常数项提出来需要平方，因此式子里面有开根号。**

1. **权重方差设置为 ( $\frac{1}{n^{[l-1]}}$ )**：这种方法通常用于激活函数如sigmoid或tanh，其中 ( n ) 是神经元的输入特征数量。这样做可以保持网络各层激活值的分布一致，有助于梯度在深层网络中稳定传播。
2. **权重方差设置为 ( $\frac{2}{n^{[l-1]}}$ )**：当使用ReLU激活函数时，推荐的方差设置为 ( $\frac{2}{n^{[l-1]}}$ )，如果我们初始化权重使得其方差为 ($\frac{2}{n^{[l-1]}}$)，那么由于ReLU的非负性，经过激活函数后的输出方差将会减半，因为输入的一半期望会被ReLU置为0。为了补偿这种减半的效果，我们将权重的方差初始化为 ( $\frac{2}{n^{[l-1]}}$)，这样经过ReLU函数后，输出的方差期望仍然是1，从而保持了信号在网络层之间传播时的稳定性。
  4. **零均值和单位方差**：如果输入特征被标准化为零均值和单位方差（即均值为0，方差为1），那么通过权重矩阵的线性变换后，输出 ( z ) 也会倾向于有相似的分布。这是因为标准化输入意味着输入特征在不同维度上是可比的，且没有一个维度会在计算 ( z ) 时主导其他维度。这有助于避免某些权重在训练过程中变得过大或过小，从而保持梯度的稳定。

​	通过调整权重的初始方差，我们可以确保在网络的每一层，信号的分布保持一致，不会随着网络深度的增加而发生显著的放大或衰减。这有助于维持梯度的稳定性，使其既不会爆炸也不会消失。

### He初始化

$$
W = np.random.randn(shape)\times \sqrt{\frac{2}{n^{[l-1]}}}
$$



- ( W ) 表示权重矩阵。
- `np.random.randn(shape)` 是一个生成形状为 `shape` 的数组的函数，数组中的值遵循标准正态分布（均值为0，标准差为1）。
- ( n^{[l-1]} ) 表示前一层的节点数。
- ( \sqrt{\frac{2}{n^{[l-1]}}} ) 是一个缩放因子，用于调整权重的方差，使其适应ReLU激活函数。
- He初始化适用使用ReLU激活函数的网络层。

#### 原因

​	深度神经网络中，如果每层的权重初始化不当，那么在多层传播过程中，激活值和梯度可能会迅速增长或减少，导致梯度爆炸或消失。方差是衡量数据分布离散程度的统计量，**如果每层的输出方差能够保持一致，那么激活值和梯度就能在合理的范围内传播，从而有助于网络的稳定训练。**

​	举个例子，假设我们有一个深度神经网络，每层都使用ReLU激活函数。如果我们不控制权重的初始化，使得每层的输出方差都很大，那么随着层数的增加，激活值和梯度可能会变得非常大，导致梯度爆炸。相反，如果输出方差太小，那么激活值和梯度可能会迅速减少到接近0，导致梯度消失。通过控制权重的初始化，如使用He初始化，我们可以确保每层的输出方差保持一致，从而避免这些问题。

**He初始化的推导基于几个假设：**

1. 网络层的权重是独立同分布的，并且有零均值。

2. 网络层的输入也是独立同分布的，并且有零均值和单位方差。

3. ReLU激活函数在正数部分是线性的，并且在负数部分输出为零。

​	在这些假设下，当我们计算层的输出 ( z = Wx + b )（其中 ( b ) 是偏置项，通常初始化为0）时，输出 ( z ) 的每个元素是输入特征和权重的乘积之和。由于输入特征和权重都是独立同分布的，我们可以使用方差的性质来计算 ( z ) 的方差。如果权重的方差是 ( $\frac{1}{n^{[l-1]}}$)，那么 ( z ) 的方差将是 ($ n^{[l-1]} \times \frac{1}{n^{[l-1]}} = 1$ )。但是，由于ReLU函数在负数部分的输出为零，这意味着实际上只有一半的神经元会对下一层的激活值产生贡献。因此，为了保持激活值的方差，我们需要将权重方差加倍，即 ( $\frac{2}{n^{[l-1]}}$ )。

​	这样，当我们应用ReLU函数 ( $a = \text{ReLU}(z)$ ) 时，激活值 ( a ) 的方差将保持为1，这有助于在网络的各个层中保持较为一致的激活值和梯度的分布。

![image-20240609005713001](images/image-20240609005713001.png)

### Xavier初始化

​	Xavier初始化的核心思想是保持输入和输出的方差一致，从而保持整个网络中激活值的方差。这样做可以帮助梯度更均匀地流过网络，使得网络更容易学习。
$$
W = np.random.randn(\text{shape}) \times \sqrt{\frac{2}{n_{\text{in}} + n_{\text{out}}}}
$$
其中：

- ( W ) 是权重矩阵。

- `np.random.randn(shape)` 生成一个形状为 `shape` 的数组，数组中的值遵循标准正态分布（均值为0，标准差为1）。

- ($ n_{\text{in}}$ ) /($ n^{[l-1]}$ ) 是权重矩阵的输入单元数。

- ($ n_{\text{out}} $)/($n^{[l]}$) 是权重矩阵的输出单元数。

- 适用于激活函数是线性或者是tanh这样在输入为0附近近似线性的函数。

#### 原因

Xavier基于以下数学推导和统计假设：

1. 网络层的权重 ( W ) 是独立同分布的，并且有零均值。

2. 网络层的输入 ( x ) 也是独立同分布的，并且有零均值和单位方差。

3. 激活函数在输入为0附近是线性的，这使得在初始化阶段可以近似认为激活函数是恒等函数。

​	在这些假设下，对于前向传播，我们希望每层的激活值 ( a ) 的方差保持不变，即 ($ \text{Var}(a^{[l]}) = \text{Var}(a^{[l-1]}) $)。考虑到激活值 ( a ) 是权重 ( W ) 和输入 ( x ) 的乘积之和，我们可以得到：
$$
\text{Var}(a) = \text{Var}\left(\sum_{i=1}^{n_{\text{in}}} W_i x_i\right) = n_{\text{in}} \text{Var}(W) \text{Var}(x)
$$
​	由于 ( x ) 的方差是1，为了使 ( $\text{Var}(a)$ ) 保持不变，我们需要 ($ \text{Var}(W) $) 为 ( $\frac{1}{n_{\text{in}}} $)。但是，这只考虑了前向传播。

​	对于反向传播，我们还需要考虑输出节点的数量 ($ n_{\text{out}} $)，因为梯度也会通过权重传播回去。因此，为了在前向传播和反向传播中都保持方差稳定，Xavier初始化选择了 ( $n_{\text{in}}$ ) 和 ($ n_{\text{out}}$ ) 的平均值，即 ( $\frac{2}{n_{\text{in}} + n_{\text{out}}}$ )。

​	所以，当我们从标准正态分布中抽取权重并乘以 ($ \sqrt{\frac{2}{n_{\text{in}} + n_{\text{out}}}}$ ) 时，我们就能保证在网络的每一层中，无论是在前向传播还是在反向传播中，激活值和梯度的方差都保持**大致**相同，从而避免了梯度爆炸或消失的问题。

## 4.2-梯度的数值逼近

​	使用双边差分和不使用单边差分来逼近导数，其结果误差更小。对于双边差分他的逼近误差可以写为O(ε²)而单边差分的逼近误差则为O(ε)。

​	单边差分和双边差分。在数值微分中，我们通常使用差分来逼近导数，因为在计算机上直接计算导数的极限是不可能的。我们通过计算函数在某点附近的变化来估计导数。

​	**单边差分（单边误差）**是指只考虑函数在某一点的一侧（例如，只考虑点 ( x + $\epsilon$ )）来逼近导数。其公式为：
$$
\approx \frac{f(x + \epsilon) - f(x)}{\epsilon}
$$
​	**双边差分（双边误差）**则考虑了函数在该点的两侧（即点 ( x +$ \epsilon$ ) 和 ( x -$ \epsilon$ )），其公式为：
$$
\approx \frac{f(x + \epsilon) - f(x - \epsilon)}{2\epsilon} 
$$


​	在泰勒级数展开中，双边差分的误差项是 ( $\epsilon^2 $) 的高阶项，而单边差分的误差项是 ( $\epsilon $) 的高阶项。这意味着随着 ($ \epsilon$ ) 的减小，双边差分的误差会比单边差分的误差减小得更快。![image-20240609115205958](images/image-20240609115205958.png)

## 4.3-梯度检验

​	执行梯度检验首先要做的是把所有参数转换为一个巨大的向量数据，将这些参数，例如权重矩阵 ( W ) 和偏置向量 ( b )，展平成一个长向量 ( $\theta$ )，这样就可以将梯度检验的过程统一化，对每个参数进行相同的操作，然后使用dw<sup>[L]</sup>和db<sup>[L]</sup>来初始化大向量dθ，它与θ有相同的维度。

​	梯度检验过程中，计算数值梯度作为梯度的近似值，并将其与反向传播得到的梯度进行比较。如果两者之间的差异很小，那么我们就可以认为反向传播算法是正确的。为了计算数值梯度，我们需要对每个参数 ($ \theta_i $) 分别进行双边差分，然后观察目标函数 ( J ) 的变化。

​	现在成本函数J是超级参数θ的一个函数，计算dθ<sub>approx</sub><sup>[i]</sup>（逼近值）的值，使用双边差分，将θ分为(θ<sub>1</sub>,θ<sub>2</sub>,......,θ<sub>i</sub>),然后求其偏导数，然后使用for循环对其每一个都求偏导。

​	**θ分为(θ<sub>1</sub>,θ<sub>2</sub>,......,θ<sub>i</sub>)的实际例子：**我们有一个权重向量 ( $\theta$ )，它包含了所有的权重参数 ( $\theta_1, \theta_2, \ldots, \theta_n$ )。如果我们有一个特征向量 ( x ) 和对应的权重向量 ($ \theta $)，那么模型的预测 ( $\hat{y} $) 可以通过向量内积来计算：
$$
\hat{y} = \theta^T x = \sum_{j=1}^{n} \theta_j x_j
$$
​	在执行梯度检验时，我们通常会计算两个向量之间的距离，即梯度的逼近值 ($ d\theta_{approx} $) 和实际的梯度 ( $d\theta $)。这个距离可以通过计算两个向量的欧几里得范数来得到，然后将其归一化，以便比较不同规模的参数。具体来说，我们计算的是：
$$
\frac{||d\theta_{approx} - d\theta||_2}{||d\theta_{approx}||_2 + ||d\theta||_2}
$$
​	这个比率被称为相对误差。当相对误差非常小，比如小于 ( $10^{-7} $)，这通常意味着梯度的逼近非常接近实际的梯度，表明梯度计算是正确的。如果相对误差在 ( $10^{-5}$ ) 到 ( $10^{-4}$ ) 之间，可能还可以接受，但需要谨慎；如果相对误差大于 ($10^{-3}$ )，则很可能计算中存在错误。

![image-20240609121210716](images/image-20240609121210716.png)

## 注意事项

1. **不要在训练就使用梯度检验，其仅适用于调试：** 梯度检验是计算密集型的，因为它需要对每个参数进行至少两次前向传播（对于双边差分）。如果在每次训练迭代中都进行梯度检验，将大大增加训练时间。因此，梯度检验通常仅在调试阶段使用，以验证梯度计算的正确性。

2. **梯度检验失败时的调试方法**：在梯度检验中，如果发现 ($d\theta_{approx}^{[i]}$ ) 与 ( $d\theta$ ) 之间的差异很大，这通常意味着在计算梯度时可能存在错误。这种情况下，我们需要逐个检查每个参数的梯度，以确定问题的具体位置。

   - 当我们发现某些层的 ( $db^{[L]}$ ) 的梯度检验失败（即 ( $d\theta_{approx}^{[i]}$ ) 与 ($ d\theta$ ) 差异很大），而相应层的 ( $dw^{[L]}$ ) 的梯度检验却通过了（即 ( $d\theta_{approx}^{[i]} $) 与 ($ d\theta$ ) 非常接近），这表明问题可能出在偏置参数 ( b ) 的梯度计算上。在神经网络中，权重 ( w ) 和偏置 ( b ) 是分开计算的，它们对应于不同的参数和梯度。如果 ( dw ) 的计算是正确的，但 ( db ) 的计算是错误的，那么这表明反向传播算法在计算偏置梯度时可能出现了问题。

     同样，如果某个特定的 ( $d\theta_{approx}^{[i]}$ ) 与 ( $d\theta$ ) 差异很大，而其他的梯度检验都通过了，那么这个特定的$ ( i ) $值可能指向了问题所在的参数。例如，如果这个$ ( i )$ 值对应于某一层的$dw$，那么问题可能出在这一层的权重梯度计算上。

3. **正则化项的影响**：在进行梯度检验的时候，如果使用正则化去除过拟合现象，请注意正则化项：即代价函数J<img src="images/image-20240609133439575.png" alt="image-20240609133439575" style="zoom: 67%;" />则计算dθ的时候要包括这个正则化的项。正则化项会影响梯度的值，如果在梯度检验中忽略了正则化项，将导致数值梯度与实际梯度不匹配。

4. **梯度检验与dropout的不兼容性**：Dropout是一种正则化技术，它通过随机丢弃网络中的一些单元来防止过拟合。由于dropout的随机性，每次迭代中丢弃的单元都不同，这使得梯度的计算变得不确定，难以计算dropout在梯度下降上的代价函数J。因此，在进行梯度检验时，应关闭dropout。

5. **梯度检验与参数初始化的关系**：参数初始化对于模型的训练和梯度检验都非常重要。参数 ( w )（权重）和 ( b )（偏置）的初始值会影响梯度下降算法的效率和梯度检验的准确性。当权重 ( w ) 和偏置 ( b ) 接近0时，意味着模型在开始训练时没有强烈的偏见，有助于模型更公平地探索权重空间，从而找到损失函数的全局最小值。其次，这种初始化方法有助于避免权重的对称性问题，即避免所有神经元都学习到相同的特征。

   然而，当 ( w ) 和 ( b ) 的值变大时，模型可能会进入激活函数的饱和区域，特别是当使用像Sigmoid或Tanh这样的激活函数时。在这些区域，激活函数的梯度非常小，这会导致梯度消失问题，使得梯度下降难以继续更新权重。此外，大的权重值也可能导致梯度爆炸，特别是在深层网络中，这会使得梯度下降无法稳定地收敛。

   在网络训练之前使用较小的随机值进行参数初始化，并进行梯度检验，是为了确保反向传播算法正确实施，梯度计算准确无误。这一步是在训练开始前的一个重要的验证步骤，因为此时参数还没有经过任何训练，数值稳定性问题较小。随着训练的进行，参数 ( w ) 和 ( b ) 会更新并远离初始值。如果在训练过程中进行梯度检验，由于参数值的增大，可能会遇到数值稳定性问题，导致梯度检验不再准确。此外，训练过程中引入的如动量、自适应学习率等优化技术，也会影响梯度的计算，使得梯度检验的结果不再可靠。因此，梯度检验通常在训练开始前进行，以验证梯度计算的正确性。一旦开始训练，就应该依赖于其他方法（如监控训练/验证损失）来确保模型的学习过程是正确的。

# Mini-batch梯度下降算法

​	前方我们已经经历过将数据集等进行矩阵化，但当数量庞大时，例如样本数为上百万千万，则运行速度依旧很慢。

​	在对整个训练集执行梯度下降法的时候，必须先处理整个训练集，然后才可以进行下一步梯度下降算法，然后你需要再重新处理百万个训练样本，才能进行下一步梯度下降算法。有一种更快的算法既是整个百万个样本的训练集之前，先让梯度下降算法处理一部分，则算法速度会更快。

1.把训练集分割为小一点的子训练集，这些子集被取名Mini-batch，假设每一个子集中有1000个样本，即x<sup>(1)</sup>和x<sup>(1000)</sup>取出来,将其称为第一个子训练集，x<sup>(1)</sup>和x<sup>(1000)</sup>把这个叫做x<sup>{1}</sup>,以此类推，假设共有5000个$Mini-batch$，则总数就为500万个。

2.对$Y$做相同的处理，

3.Mini-batch的数量t组成了x<sup>{t}</sup>和y<sup>{t}</sup>输入输出对。

4.batch即是同时处理所有的数据集，Mini-batch既是单个的Mini-batch的x<sup>{t}</sup>和y<sup>{t}</sup>输入输出对。

![image-20240621004423844](images/image-20240621004423844.png)

​	下图是进行$Mini-batch$的伪代码，简单来说就是一次处理1000个数据，以x<sup>{t}</sup>和y<sup>{t}</sup>为单位，其好处是一次遍历就下降了5000次梯度算法。

![image-20240621005014546](images/image-20240621005014546.png)

1. **Mini-batch 梯度下降法**：
   - 在传统的梯度下降法中，需要在每一次迭代中计算整个训练集的梯度，然后更新模型参数。但是，当训练集非常大时，这会变得非常耗时。
   - Mini-batch 梯度下降法通过将训练集分成小的子集（即 $Mini-batch$），每次只使用一个 $Mini-batch$ 来计算梯度和更新参数。这样，可以更频繁地更新模型，而不必等待整个训练集的处理。
2. **Mini-batch 的好处**：
   - **加速收敛**：$Mini-batch$ 允许更频繁地更新模型参数，从而加速收敛。相比于使用整个训练集的梯度，$Mini-batch$ 可以更快地找到局部最优解。
   - **减少内存需求**：使用整个训练集的梯度需要大量内存，而 $Mini-batch$ 只需要存储一个小的子集，因此内存需求更低。
   - **降低计算复杂度**：计算 Mini-batch 的梯度比整个训练集更快，因为它只涉及部分数据。
3. **选择 Mini-batch 大小**：
   - Mini-batch 的大小是一个超参数，需要根据具体问题进行调整。通常，较小的 $Mini-batch$ 可以更频繁地更新模型，但也会增加噪声。较大的 $Mini-batch$ 可以减少噪声，但更新频率较低。
   - 常见的 Mini-batch 大小包括 32、64、128 等。

## 5.1-理解Mini-batch 梯度下降法

​	对于其迭代-成本函数关系图，因为$Mini-batch$每次都在训练不同的样本，因此其总体呈下降趋势但噪音较多，产生噪音的原因在于也许x<sup>{1}</sup>和y<sup>{1}</sup>是比较容易计算的$Mini-batch$，因此成本会低一点；而x<sup>{2}</sup>和y<sup>{2}</sup>是比较难九三的Mini-batch这样成本会高一点，因此才会出现波动。

![image-20240621010529196](images/image-20240621010529196.png)

1. **Mini-batch 梯度下降法**：
   - Mini-batch 梯度下降法将训练集分成小的子集（Mini-batch），每次只使用一个 Mini-batch 来计算梯度和更新参数。
   - 这样做的好处是既能加速收敛，又能减少内存需求，但也引入了一些噪音。
2. **噪音的原因**：
   - Mini-batch 的大小是一个超参数，通常比整个训练集小得多。因此，每个 Mini-batch 只包含一部分样本，而不是全部。
   - 噪音主要来自于 Mini-batch 中样本的随机性。不同 Mini-batch 中的样本可能具有不同的特性，导致梯度的估计有一定的波动。
3. **成本函数图的特点**：
   - 成本函数图在 Mini-batch 梯度下降法中呈现出波动的特点，因为每个 Mini-batch 的样本不同，导致每次计算的成本函数值也不同。
   - 总体趋势是下降的，但由于噪音，成本函数图会有一些起伏。
4. **随机梯度下降法**：
   - 当 Mini-batch 的大小为 1 时，我们得到了随机梯度下降法。
   - 随机梯度下降法每次只使用一个样本来计算梯度，因此成本函数图会更加嘈杂，不会收敛到最小值，而是在最小值附近波动。
   - 这种方法的效率较低，因为它失去了向量化带来的好处。

![image-20240621011406101](images/image-20240621011406101.png)

# 指数加权平均

​	又名指数加权移动平均，下图为温度的散点图，如果计算温度的局部平均值（移动平均值）步骤如下。

​	**指数加权移动平均（EMA）的公式**：

- 假设第i天的温度为$θ_i$，我们要计算第$i$天的EMA。

- 初始值：$V_0 = 0$（通常设置为0，但也可以根据实际情况选择其他初始值）。

- EMA的计算公式：
  $$
  V_i = \beta V_{i-1} + (1 - \beta) \theta_i
  $$
  

  其中，$β$是权重系数，通常取0.9或0.98。

  ![image-20240621014439569](images/image-20240621014439569.png)

![image-20240621012151127](images/image-20240621012151127.png)

​	其计算结果近似等于图片中公式，也即多少天温度。

​	平均更多的值，指数加权平均公式在温度变化时，适应地更缓慢一些，所以会出现一定的延迟，当$β=0.98$，相当于给前一天值加了太多权重，只有0.02的权重给了当日的值，所以温度变化时，温度上下起伏，当$β$较大时，指数加权平均值适应地更慢一些。

**权重系数 β 的作用**：

- β 控制了历史数据的权重。较大的 β 会使EMA更加平滑，适应变化较慢，而较小的 β 会使EMA更加敏感，更快地适应变化。
- 当 β 接近1时，EMA对历史数据的依赖性较高，因此变化较慢。例如，当 β=0.98 时，只有0.02的权重给了当日的值，前一天的值占据了很大的权重。
- 当 β 较小（例如，β=0.5）时，EMA更快地适应温度变化，因为它平均了较短时间内的数据。

**EMA的优点**：

- EMA对噪声和短期波动具有抑制作用，因此在趋势分析、股票价格预测、信号处理等领域中广泛应用。
- 它能够平滑数据，减少随机波动，使趋势更明显。

![image-20240621012930191](images/image-20240621012930191.png)

## 6.1-理解指数加权平均

​	所谓加权平均，以$V_{100}$为例子，当$β=0.90$的时候，在0.9的10次方后，其值大约等于$\frac{1}{e}$,也即大约平均了从100往前的十天数据，这个天数计算就以$\frac{1}{1-β}$来算，所以当$β=0.98$，在0.98的50次方后其值大约等于$\frac{1}{e}$。

![image-20240621014321766](images/image-20240621014321766.png)

**指数加权平均的衰减因子**：

- $β $决定了EMA对历史数据的依赖程度。较大的$ β $会使EMA更加平滑，适应变化较慢，而较小的 $β$ 会使EMA更加敏感，更快地适应变化。
- 当$ β $接近1时，EMA对历史数据的权重较高，因此变化较慢。我们可以将$ \frac{1}{1−β}$ 视为EMA的衰减因子，表示EMA对历史数据的衰减速度。

## 6.2-指数加权平均的偏差修正

​	偏差修正可以让平均数运算的更加准确、当$β=0.98$时候，偏差修正使得曲线不再为绿而是紫色，右边既是偏差修正，随着天数t的增加，分母趋近于1，即不再有修正作用，这就是为什么后半部分会重合。

![image-20240621015254891](images/image-20240621015254891.png)

**偏差修正的作用**：

- 偏差修正的目标是消除初始数据对EMA的影响，使得EMA更准确地反映历史数据的平均趋势。

- 偏差修正的公式为：
  $$
  \hat{V}_i = \frac{V_i}{1 - \beta^i}
  $$
  

  其中，$V^i$ 是经过偏差修正后的EMA值。

- 注意，分母中的$1−β^i$是一个递增的因子，随着天数$i$的增加而逐渐接近1。

**偏差修正的效果**：

- 当$ i $较小时，分母接近1，偏差修正的效果较小。
- 随着$ i $的增加，分母逐渐减小，偏差修正的作用逐渐显现。
- 当$ i$ 较大时，分母接近1，偏差修正不再起作用，此时的EMA值与未修正的EMA值相同。

**为什么后半部分会重合**：

- 当$ i $较大时，偏差修正的效果逐渐减小，EMA值趋于稳定。
- 因此，后半部分的EMA曲线与未修正的EMA曲线重合，不再有明显的差异。

# 动量(Momentum)梯度下降法

​	基本想法为计算梯度的指数加权平均数，并利用该梯度更新你的权重，下图中在靠近最小值的时候，上下的波动减慢了梯度下降算法的速度，无法使用更大的学习率，如果使用更大的学习率，结果可能会偏离函数的范围，如紫线所示。

​	因此我们想要在纵轴上学习慢一点以减缓波动的产生，而加速横轴的学习速度.

​	Momentum梯度下降法即在第t次迭代中，计算$batch或者mini-batch$微分$dw,db$，利用此来计算$dw,db$，计算公式如下。
$$
V_{dW}=β*V_{dW}+(1-β)*dW
$$

$$
V_{db}=β*V_{db}+(1-β)*db
$$

$$
W=W-α*V_{dW};b=b-α*V_{db}
$$

​	因为纵轴是上下摆动，因此指数加权平均会使得平均值近似为0，而纵轴总体向一个方向，速度会更快。

![image-20240621021015289](images/image-20240621021015289.png)

​	通常β的值为0.9具有鲁棒性，$v_{dW},v_{db}$通常初始化为0。

![image-20240621021243088](images/image-20240621021243088.png)

# RMSPROP

​	与动量梯度算法目标一致，使得纵轴速度减缓，横轴速度增加，在第t次迭代中，算法会照常计算$batch或者mini-batch$微分$dw,db$，并利用以下公式计算。![image-20240621022553580](images/image-20240621022553580.png)
$$
S_{dW}=β*S_{dW}+(1-β)*(dW)^2
$$

$$
S_{db}=β*S_{db}+(1-β)*(db)^2
$$

$$
W=W-α*\frac{V_{dW}}{\sqrt{S_{dW}+ε}};b=b-α*\frac{V_{db}}{\sqrt{S_{db}+ε}}
$$

​	在纵轴上斜率较大，因此$S_{db}$大，也即$b$方向会小，减少抖动；横轴同理。为了避免分母为0，通常会改写为$S_{dW}+ε，ε通常取10^{-8}$。

![image-20240621025213839](images/image-20240621025213839.png)

​	此时可以使用较大的学习率。

# Adam优化算法

首先初始化，$V_{dW}=0,S_{dW}=0,V_{dB}=0,S{dB}=0$,在第t次迭代中，算法会照常计算$batch或者mini-batch$微分$dw,db$，并利用以下公式计算。
$$
V_{dW}=β_1*V_{dW}+(1-β)*dW,V_{db}=β_1*V_{db}+(1-β)*db
$$

$$
S_{dW}=β_2*S_{dW}+(1-β)*(dW)^2,S_{db}=β_2*S_{db}+(1-β)*(db)^2
$$

$$
{{V}_{dw}}^{corrlected} = \frac{V_{dw}}{1 - \beta^t_1},{{V}_{db}}^{corrlected} = \frac{V_{db}}{1 - \beta^t_1}
$$

$$
{{S}_{dw}}^{corrlected} = \frac{S_{dw}}{1 - \beta^t_2},{{S}_{db}}^{corrlected} = \frac{S_{db}}{1 - \beta^t_2}
$$

$$
W=W-α*\frac{{V_{dW}}^{collected}}{\sqrt{S_{dW}+ε}},b=b-α*\frac{{V_{db}}^{collected}}{\sqrt{S_{db}+ε}}
$$

![image-20240621024706261](images/image-20240621024706261.png)

推荐数值![image-20240621024639409](images/image-20240621024639409.png)
