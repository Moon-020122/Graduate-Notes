# 训练、开发、测试集

1. **训练集 (Training Set)**:

   - **作用**：训练集用于训练机器学习模型。模型通过观察训练集中的样本来学习数据的模式、特征和关系。
   - **示例**：假设构建一个垃圾邮件分类器。训练集将包含已标记为“垃圾邮件”或“非垃圾邮件”的电子邮件样本。模型将使用这些样本来学习如何区分垃圾邮件和非垃圾邮件。

2. **验证集 (Validation Set)**:

   - **作用**：验证集用于调整模型的超参数（例如学习率、正则化参数等）。它帮助我们选择最佳的模型配置，以避免过拟合或欠拟合。
   - **示例**：在训练过程中，使用验证集来评估不同超参数设置的性能。例如，可以尝试不同的隐藏层大小、学习率等，并选择在验证集上表现最好的模型。

3. **测试集 (Test Set)**:

   - **作用**：测试集用于评估模型的泛化能力。是模型在未见过的数据上的性能指标。

   - **示例**：在训练和验证之后，使用测试集来评估模型的准确性、召回率、精确度等指标。测试集中的样本与训练集和验证集中的样本不重复，以确保模型在新数据上的表现。

# 偏差、方差

对于下方照片，第一个是高偏差的情况，中间为适度拟合，右边为高度拟合。![image-20240605200531746](images/image-20240605200531746.png)

理解偏差和方差的两个关键数据是训练集误差和验证集误差。

**高方差：**即高度拟合，训练集效果好，验证集效果差，如训练集的误差为1%而验证集的误差为11%。

**高偏差：**即训练集的错误率高，也即欠拟合，和验证集的结果却较为合理。如训练集的误差为15%而验证集的误差为16%。

**高偏差且高方差：**即训练集的错误率高的同时，验证集的结果也不合理。如训练集的误差为15%而验证集的误差为30%。

如训练集的误差为0.5%，验证集的误差为1%，则是低偏差低方差，为模型优秀结果。

**最优误差(基本误差)：**如果假设人类的识别程度的错误率为15%，那么验证集的错误率15%也为合理情况。

如果出现高偏差的情况无法拟合训练集，则选择新的网络；如果偏差适合的情况下，方差高则最好的解决办法就是采用更多数据或者正则化来减少拟合。

## 2.1-正则化

​	一般用于高方差的情况下；**正则化**（Regularization）：用于控制模型的复杂度，防止模型在训练数据上过度拟合（overfitting）。当模型过度拟合时，它会学习到训练数据中的噪声和细微变化，导致在新数据上的性能下降。

![image-20240605205134599](images/image-20240605205134599.png)

**L1 正则化**:

- **数学形式**

  : L1 正则化通过在损失函数中添加权重参数的绝对值之和作为惩罚项。这可以表示为损失函数 ![image-20240605205320014](images/image-20240605205320014.png)加上正则化项![image-20240605205344967](images/image-20240605205344967.png)

  **效果**: L1 正则化倾向于产生稀疏的权重矩阵，即许多权重会变为零。这意味着它可以用于特征选择，因为它会自动去除不重要的特征（权重为零的特征）。
  
  **L1范数**（也称为曼哈顿距离）：
  
  - **定义**：L1范数是向量中各个元素绝对值之和。
  - **作用**：L1范数倾向于产生稀疏的权重矩阵，即许多权重会变为零。因此，它可以用于特征选择。
  - **示例**：在对用户的电影爱好进行分类时，L1范数可以过滤掉无用的特征，只保留对分类有用的特征

**L2 正则化**（权重衰减）:

- **数学形式**:

   L2 正则化通过在损失函数中添加权重参数的平方和作为惩罚项。这可以表示为损失函数![image-20240605205320014](images/image-20240605205320014.png)加上正则化项![image-20240605205523676](images/image-20240605205523676.png)

  **效果**: L2 正则化会使权重值变得较小，但不会将它们推向零，这意味着它不会产生稀疏模型。L2 正则化有助于控制模型的复杂度，但不具备特征选择的功能。

  **L2范数**（弗罗贝尼乌斯范数）（也称为欧氏距离）：

  - **定义**：L2范数是向量元素平方和再开平方。
  - **作用**：L2范数不会将权重推向零，但会使权重变得较小，从而防止过拟合。
  - **示例**：在模型优化中，L2范数通常用作正则化项，以提高模型的泛化能力。

![image-20240605214643543](images/image-20240605214643543.png)

​	当λ足够大时，它会对权重矩阵施加很大的惩罚，导致权重的值减小，甚至趋于0。神经网络会越来越接近逻辑回归，但神经网络的隐藏单元依旧存在，只不过影响变小了。

​	损失函数中加入L2正则化项时，算法会尝试最小化损失函数和正则化项的总和（成本函数）。由于正则化项是权重的平方和，增加λ会使得优化算法在减少损失的同时，也倾向于将权重值减小，以降低正则化项的值。如果λ设置得非常大，那么优化算法在减少正则化项的过程中，会将权重推向。

​	当权重值减小或趋于0时，隐藏单元与输入和输出之间的连接变得非常弱。意味着隐藏单元对模型的输出贡献减少，从而减少了它们的影响力。虽然隐藏单元仍然存在，但对最终结果的影响也会变得很小，使得整个网络的行为更像是一个简单的逻辑回归分类器。

![image-20240607122958629](images/image-20240607122958629.png)

### **为什么正则化可以减少过拟合？**

​	即正则化通过添加一个与权重相关的惩罚项到损失函数中，鼓励模型学习更小的权重，而这样会使得模型倾向于学习更简单的、泛化能力更强的模式，而不是复杂的模式，这些复杂的模式可能只在训练数据上有效，但在未见过的数据上则不一定有效（过拟合）。

​	以tanh激活函数为例，当正则化参数λ增大，导致权重w减小，因为z是输入x和权重w的线性组合，所以z的值也会减小。当z的值较小时，tanh函数的输出接近线性关系（因为tanh函数在原点附近是近似线性的，如图所示）。这意味着，随着λ的增加，神经网络的非线性效应减弱，模型的复杂度降低，从而减少了过拟合的风险。

tanh函数可以表示为：
$$
\text{tanh}(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}}
$$
当z的值较小（即接近0）时，tanh函数可以近似为：
$$
\text{tanh}(z) \approx z
$$
![image-20240607123827795](images/image-20240607123827795.png)

## 2.2-dropout(随机失活)正则化

dropout会遍历网络的每一层，并设置消除神经网络中节点的概率，假设我们设置每一层的消除概率为0.5，即理论上有一半的隐藏单元会被消除，那么这个消除后的神经网络既是正则化后的神经网络。

​	通过在训练过程中随机地丢弃（即将权重设置为0）网络中的一部分神经元来减少过拟合。在每一层设置一个丢弃概率。如0.5，则在每次训练迭代中，每个神经元都有50%的概率不被包括在前向和后向传播中。这样，网络的每次训练迭代都是在一种略微不同的网络架构下完成的。

​	这种方法的效果类似于训练多个不同的网络，并将它们的预测结果进行平均。因为每次迭代都随机丢弃不同的神经元，所以实际上是在训练多个“子网络”。这些子网络共享权重，因此dropout可以被看作是一种非常高效的模型集成方法。

![image-20240607130819065](images/image-20240607130819065.png)

### inverted dropout（反向随机失活）

​	keep-prob是一个概率，意味为1的概率是多少，此处为0.8即80%为1，20%为0，后将a3(第三层输出)与d3相乘，然后将a3中对应于d3中为0的位置置1，也即是完成了消除。

​	在使用dropout正则化时，除以keep-prob（保留概率）是为了保证激活值的期望不变。在dropout过程中，一部分神经元会被随机丢弃，从而减少了网络的有效容量。如果不进行调整，那么在训练阶段，神经元的输出激活值的期望会因为dropout而减少。

​	例如，假设keep-prob为0.8，这意味着有20%的神经元会被丢弃。剩下的神经元的输出激活值的总和将只有原来的80%，这会影响到后续层的学习过程。我们需要将激活值除以keep-prob，这样在期望上，激活值的总和仍然保持不变。假设一个神经元的输出激活值为 ( a )，在不使用dropout的情况下，其期望值为 ( a )。如果使用了dropout，神经元的输出激活值的期望变为 ：
$$
\text{keep-prob} \times a
$$
​	为了使期望值与不使用dropout时一致，我们需要将激活值除以keep-prob，即：
$$
\frac{\text{keep-prob} \times a}{\text{keep-prob}} = a
$$
![image-20240607132538222](images/image-20240607132538222.png)

​	而在测试阶段不用使用dropout。其原因是，我们希望模型能够利用其全部学到的知识来进行预测，而不是依赖于训练时的随机性。Dropout是一种正则化技术，它通过在训练过程中随机地关闭一部分神经元来防止模型过拟合。这种随机性有助于模型学习到更加鲁棒（鲁棒性（Robustness）指的是系统在面对各种变化、干扰或不确定性时，仍能保持正常运行和正确输出结果的能力。）的特征表示，因为它不能依赖于任何特定的神经元激活模式。

​	在测试阶段，我们需要模型给出稳定的预测结果。如果在测试时也使用dropout，那么每次运行模型时都可能得到不同的结果，因为不同的神经元会被随机关闭。这会导致模型的预测性能下降，因为我们无法保证模型每次都能使用最佳的神经元组合来做出决策。由于在训练阶段使用了dropout，模型的权重已经适应了在一定比例的神经元被关闭的情况下进行预测。因此，在测试阶段，我们可以使用所有的神经元（即不使用dropout），但权重可能会乘以保留概率（keep-prob），以保持激活值的总和与训练阶段相似。这样做可以确保模型的输出反映了训练时学到的所有知识，同时保持了预测的一致性。

### 理解dropout

​	Dropout作为一种正则化技术，会随机地关闭网络中的一些单元，这样做的目的是为了防止网络对于训练数据的过度拟合。当一个单元被关闭时，它在当前训练迭代中不会对前向传播和反向传播产生影响。这迫使网络不会对任何一个输入特征赋予过多的权重，因为在训练过程中，这些特征可能会被随机删除。因此，网络必须学习更加分散的权重，以便在某些输入特征缺失时仍能做出准确的预测。

​	Dropout的效果类似于L2正则化，因为它倾向于减小权重的大小，但它们的工作原理有所不同。L2正则化通过惩罚权重的平方和来工作，导致所有权重都均匀地缩小，特别是对于那些较大的权重。而Dropout则是通过随机地关闭单元来实现正则化，这种方法不是均匀地缩小权重，而是增加了权重配置的多样性。

​	对于不同层应用不同的keep-prob（保留概率），因为不同的层可能对过拟合的敏感度不同。例如，如果某个权重矩阵特别大，可能需要更高的dropout率来防止过拟合；而对于那些我们认为不太可能过拟合的层，可以设置较高的keep-prob，甚至可以是1，意味着这些层不使用dropout。

​	Dropout主要用于计算机视觉领域，在这个领域中，模型往往非常深且复杂，容易过拟合。在其他类型的问题中，可能不需要使用dropout，或者使用其他形式的正则化就足够了。这取决于具体问题的复杂性、数据的数量和质量，以及模型的结构。

![image-20240607150642455](images/image-20240607150642455.png)

## 2.3-其他正则化的方法

通过改变图片的方式来伪增加图片集。![image-20240607151407146](images/image-20240607151407146.png)

#### Early stopping

​	Early stopping是一种防止神经网络过拟合的正则化技术。它的基本思想是在训练过程中，当模型在验证集上的性能不再提升时停止训练。这样做的目的是为了避免权重w变得过大，从而导致模型在训练数据上过度拟合。

​	在神经网络的训练过程中，权重w通常是从较小的随机值开始的。随着训练的进行，权重w会逐渐增大，以最小化训练集上的损失函数。如果训练时间过长，权重w可能会变得非常大，这时模型可能会开始学习训练数据中的噪声，而不是潜在的、更一般的模式，即过拟合现象。

Early stopping通过在验证集上监控性能来解决这个问题。当连续多个epoch性能没有提升时，就会停止训练。这通常意味着模型在验证集上的误差开始增加，表明模型可能开始过拟合。通过在这个“中间点”停止训练，我们可以得到一个大小适中的权重w，有助于保持模型的泛化能力，同时避免过拟合。

![image-20240607153026046](images/image-20240607153026046.png)

# 归一化输入

​	归一化输入数据是一个重要的预处理步骤，有助于算法更快地收敛并提高模型的性能。这个过程通常包括两个步骤：零均值化和方差归一化。

​	**第一步：零均值化** ，也称为中心化，指将输入变量的均值变为零。对于每个特征，我们从该特征的所有数据点中减去其平均值。数学上，如果我们有一个特征 ( X )，其均值为μ，零均值化后的特征 ( X’ ) 计算如下：
$$
\mu = \frac{1}{n}\sum_{i=1}^{n}x_i
$$

$$
X' = X - \mu
$$

​	将数据集的中心移至原点。在优化过程中，这有助于梯度下降等算法更快地找到最小值，它确保了所有特征都在同一尺度上被考虑，避免了某些特征由于数值范围大而对结果产生不成比例的影响。

​	**第二步：方差归一化** ，也称为标准化，是指将输入变量的方差变为1，当方差变为1时，这意味着数据的分布具有单位方差，也就是说，数据点在数值上相对于均值的平均距离是标准化的。这种情况下，数据的分布被称为“标准化”或“单位化”。通过将特征值除以其标准差来实现的，设特征 ( X’ ) 的标准差为 ( σ )。

​	标准差是衡量数据点偏离均值的程度的指标。首先，我们需要计算每个数据点与均值之差的平方，然后求和，最后除以数据点的数量（对于样本标准差，除以 ( n-1 )），再取平方根。标准差 (σ  ) 计算如下
$$
\sigma = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(x_i - \mu)^2} 
$$
​	则归一化后的特征 ( X’’ ) 计算如下：
$$
X'' = \frac{X'}{\sigma}
$$
​	确保了所有特征具有相同的尺度，这意味着它们对模型的贡献是平等的。例如，在使用基于距离的算法（如K-最近邻或支持向量机）时，未归一化的特征可能会由于其值的范围较大而对距离计算产生过大影响。

​	**Eg:**假设我们有两个特征，一个是人的身高（以厘米为单位），另一个是体重（以千克为单位）。身高的范围可能是150到200厘米，而体重的范围可能是50到100千克。如果直接使用这些原始数据进行机器学习，体重特征因为数值范围更大，可能会对模型产生更大的影响。但通过将这两个特征的方差都标准化为1，我们确保了它们在模型中的影响是平等的，从而使模型更加公正和有效。

![image-20240608125154838](images/image-20240608125154838.png)

## 3.1-基本原理

![image-20240608130703055](images/image-20240608130703055.png)	

​	如果使用非归一化的输入特征，代价函数会如左图所示，这是一个非常细长狭窄的成本函数；如果使用归一化，代价函数平均起来看更对称。

​	代价函数的形状会受到特征值范围的影响。如果特征 ( X_1 ) 的取值范围是 ( (0, 1000) )，而 ( X_2 ) 的取值范围是 ( (0, 1) )，那么 ( X_1 ) 在代价函数中的影响会远大于 ( X_2 )。这是因为 ( X_1 ) 的变化对代价函数的影响更大，即使它的变化很小。

​	这会导致代价函数的等高线（代价相同的点的集合）变得非常细长和狭窄，类似于左图所示。在这种情况下，梯度下降算法在不同方向上前进的速度差异很大：沿着 ( X_1 ) 方向的梯度会非常大，而沿着 ( X_2 ) 方向的梯度会非常小。因此，为了避免在 ( X_1 ) 方向上的大步长导致梯度下降超过最小值，我们需要使用一个非常小的学习率。

​	如果我们对输入特征进行归一化，使得所有特征的取值范围相似，那么代价函数的等高线会更加对称，类似于右图所示。这样，梯度下降算法在所有方向上前进的速度会更加均匀，可以使用更大的学习率，而不会有超过最小值的风险。这也意味着梯度下降算法可以更快地收敛到最小值。![image-20240608131257821](images/image-20240608131257821.png)

# 梯度消失和梯度爆炸

​	梯度爆炸或梯度消失：当训练神经网络时，导数或梯度的变化非常大或非常小，甚至以指数方式变小的现象。

​	**激活函数饱和**：使用像sigmoid或tanh这样的激活函数时，当输入值非常大或非常小，激活函数的导数接近于零，这会导致梯度消失。
​	**权重初始化**：如果权重初始化得太大，那么在网络的前向传播过程中，激活函数的输出可能会变得非常大，导致梯度在反向传播时爆炸。相反，如果权重初始化得太小，激活函数的输出可能会变得非常小，导致梯度消失。
​	**深层网络结构**：在深层网络中，梯度必须通过多个层进行反向传播。如果每层的梯度都小于1，那么最终的梯度会随着层数的增加而指数级减小，导致梯度消失。同样，如果每层的梯度都大于1，那么梯度会随着层数的增加而指数级增大，导致梯度爆炸。

![image-20240608235311723](images/image-20240608235311723.png)

## 4.1-权重初始化

​	方差衡量的是数据分布的离散程度，即数据值与其平均值的偏离程度。在神经网络中，权重的方差决定了通过该层传播的信号的分散程度。如果方差太大，信号可能会随着层数的增加而放大，导致梯度爆炸；如果方差太小，信号可能会逐渐衰减，导致梯度消失。

​	**独立同分布的方差常数项提出来需要平方，因此式子里面有开根号。**

1. **权重方差设置为 ( $\frac{1}{n^{[l-1]}}$ )**：这种方法通常用于激活函数如sigmoid或tanh，其中 ( n ) 是神经元的输入特征数量。这样做可以保持网络各层激活值的分布一致，有助于梯度在深层网络中稳定传播。
2. **权重方差设置为 ( $\frac{2}{n^{[l-1]}}$ )**：当使用ReLU激活函数时，推荐的方差设置为 ( $\frac{2}{n^{[l-1]}}$ )，如果我们初始化权重使得其方差为 ($\frac{2}{n^{[l-1]}}$)，那么由于ReLU的非负性，经过激活函数后的输出方差将会减半，因为输入的一半期望会被ReLU置为0。为了补偿这种减半的效果，我们将权重的方差初始化为 ( $\frac{2}{n^{[l-1]}}$)，这样经过ReLU函数后，输出的方差期望仍然是1，从而保持了信号在网络层之间传播时的稳定性。
  4. **零均值和单位方差**：如果输入特征被标准化为零均值和单位方差（即均值为0，方差为1），那么通过权重矩阵的线性变换后，输出 ( z ) 也会倾向于有相似的分布。这是因为标准化输入意味着输入特征在不同维度上是可比的，且没有一个维度会在计算 ( z ) 时主导其他维度。这有助于避免某些权重在训练过程中变得过大或过小，从而保持梯度的稳定。

​	通过调整权重的初始方差，我们可以确保在网络的每一层，信号的分布保持一致，不会随着网络深度的增加而发生显著的放大或衰减。这有助于维持梯度的稳定性，使其既不会爆炸也不会消失。

### He初始化

$$
W = np.random.randn(shape)\times \sqrt{\frac{2}{n^{[l-1]}}}
$$



- ( W ) 表示权重矩阵。
- `np.random.randn(shape)` 是一个生成形状为 `shape` 的数组的函数，数组中的值遵循标准正态分布（均值为0，标准差为1）。
- ( n^{[l-1]} ) 表示前一层的节点数。
- ( \sqrt{\frac{2}{n^{[l-1]}}} ) 是一个缩放因子，用于调整权重的方差，使其适应ReLU激活函数。
- He初始化适用使用ReLU激活函数的网络层。

#### 原因

​	深度神经网络中，如果每层的权重初始化不当，那么在多层传播过程中，激活值和梯度可能会迅速增长或减少，导致梯度爆炸或消失。方差是衡量数据分布离散程度的统计量，**如果每层的输出方差能够保持一致，那么激活值和梯度就能在合理的范围内传播，从而有助于网络的稳定训练。**

​	举个例子，假设我们有一个深度神经网络，每层都使用ReLU激活函数。如果我们不控制权重的初始化，使得每层的输出方差都很大，那么随着层数的增加，激活值和梯度可能会变得非常大，导致梯度爆炸。相反，如果输出方差太小，那么激活值和梯度可能会迅速减少到接近0，导致梯度消失。通过控制权重的初始化，如使用He初始化，我们可以确保每层的输出方差保持一致，从而避免这些问题。

**He初始化的推导基于几个假设：**

1. 网络层的权重是独立同分布的，并且有零均值。

2. 网络层的输入也是独立同分布的，并且有零均值和单位方差。

3. ReLU激活函数在正数部分是线性的，并且在负数部分输出为零。

​	在这些假设下，当我们计算层的输出 ( z = Wx + b )（其中 ( b ) 是偏置项，通常初始化为0）时，输出 ( z ) 的每个元素是输入特征和权重的乘积之和。由于输入特征和权重都是独立同分布的，我们可以使用方差的性质来计算 ( z ) 的方差。如果权重的方差是 ( $\frac{1}{n^{[l-1]}}$)，那么 ( z ) 的方差将是 ($ n^{[l-1]} \times \frac{1}{n^{[l-1]}} = 1$ )。但是，由于ReLU函数在负数部分的输出为零，这意味着实际上只有一半的神经元会对下一层的激活值产生贡献。因此，为了保持激活值的方差，我们需要将权重方差加倍，即 ( $\frac{2}{n^{[l-1]}}$ )。

​	这样，当我们应用ReLU函数 ( $a = \text{ReLU}(z)$ ) 时，激活值 ( a ) 的方差将保持为1，这有助于在网络的各个层中保持较为一致的激活值和梯度的分布。

![image-20240609005713001](images/image-20240609005713001.png)

### Xavier初始化

​	Xavier初始化的核心思想是保持输入和输出的方差一致，从而保持整个网络中激活值的方差。这样做可以帮助梯度更均匀地流过网络，使得网络更容易学习。
$$
W = np.random.randn(\text{shape}) \times \sqrt{\frac{2}{n_{\text{in}} + n_{\text{out}}}}
$$
其中：

- ( W ) 是权重矩阵。

- `np.random.randn(shape)` 生成一个形状为 `shape` 的数组，数组中的值遵循标准正态分布（均值为0，标准差为1）。

- ($ n_{\text{in}}$ ) /($ n^{[l-1]}$ ) 是权重矩阵的输入单元数。

- ($ n_{\text{out}} $)/($n^{[l]}$) 是权重矩阵的输出单元数。

- 适用于激活函数是线性或者是tanh这样在输入为0附近近似线性的函数。

#### 原因

Xavier基于以下数学推导和统计假设：

1. 网络层的权重 ( W ) 是独立同分布的，并且有零均值。

2. 网络层的输入 ( x ) 也是独立同分布的，并且有零均值和单位方差。

3. 激活函数在输入为0附近是线性的，这使得在初始化阶段可以近似认为激活函数是恒等函数。

​	在这些假设下，对于前向传播，我们希望每层的激活值 ( a ) 的方差保持不变，即 ($ \text{Var}(a^{[l]}) = \text{Var}(a^{[l-1]}) $)。考虑到激活值 ( a ) 是权重 ( W ) 和输入 ( x ) 的乘积之和，我们可以得到：
$$
\text{Var}(a) = \text{Var}\left(\sum_{i=1}^{n_{\text{in}}} W_i x_i\right) = n_{\text{in}} \text{Var}(W) \text{Var}(x)
$$
​	由于 ( x ) 的方差是1，为了使 ( $\text{Var}(a)$ ) 保持不变，我们需要 ($ \text{Var}(W) $) 为 ( $\frac{1}{n_{\text{in}}} $)。但是，这只考虑了前向传播。

​	对于反向传播，我们还需要考虑输出节点的数量 ($ n_{\text{out}} $)，因为梯度也会通过权重传播回去。因此，为了在前向传播和反向传播中都保持方差稳定，Xavier初始化选择了 ( $n_{\text{in}}$ ) 和 ($ n_{\text{out}}$ ) 的平均值，即 ( $\frac{2}{n_{\text{in}} + n_{\text{out}}}$ )。

​	所以，当我们从标准正态分布中抽取权重并乘以 ($ \sqrt{\frac{2}{n_{\text{in}} + n_{\text{out}}}}$ ) 时，我们就能保证在网络的每一层中，无论是在前向传播还是在反向传播中，激活值和梯度的方差都保持**大致**相同，从而避免了梯度爆炸或消失的问题。

## 4.2-梯度的数值逼近

​	使用双边差分和不使用单边差分来逼近导数，其结果误差更小。对于双边差分他的逼近误差可以写为O(ε²)而单边差分的逼近误差则为O(ε)。

​	单边差分和双边差分。在数值微分中，我们通常使用差分来逼近导数，因为在计算机上直接计算导数的极限是不可能的。我们通过计算函数在某点附近的变化来估计导数。

​	**单边差分（单边误差）**是指只考虑函数在某一点的一侧（例如，只考虑点 ( x + $\epsilon$ )）来逼近导数。其公式为：
$$
\approx \frac{f(x + \epsilon) - f(x)}{\epsilon}
$$
​	**双边差分（双边误差）**则考虑了函数在该点的两侧（即点 ( x +$ \epsilon$ ) 和 ( x -$ \epsilon$ )），其公式为：
$$
\approx \frac{f(x + \epsilon) - f(x - \epsilon)}{2\epsilon} 
$$


​	在泰勒级数展开中，双边差分的误差项是 ( $\epsilon^2 $) 的高阶项，而单边差分的误差项是 ( $\epsilon $) 的高阶项。这意味着随着 ($ \epsilon$ ) 的减小，双边差分的误差会比单边差分的误差减小得更快。![image-20240609115205958](images/image-20240609115205958.png)

## 4.3-梯度检验

​	执行梯度检验首先要做的是把所有参数转换为一个巨大的向量数据，将这些参数，例如权重矩阵 ( W ) 和偏置向量 ( b )，展平成一个长向量 ( $\theta$ )，这样就可以将梯度检验的过程统一化，对每个参数进行相同的操作，然后使用dw<sup>[L]</sup>和db<sup>[L]</sup>来初始化大向量dθ，它与θ有相同的维度。

​	梯度检验过程中，计算数值梯度作为梯度的近似值，并将其与反向传播得到的梯度进行比较。如果两者之间的差异很小，那么我们就可以认为反向传播算法是正确的。为了计算数值梯度，我们需要对每个参数 ($ \theta_i $) 分别进行双边差分，然后观察目标函数 ( J ) 的变化。

​	现在成本函数J是超级参数θ的一个函数，计算dθ<sub>approx</sub><sup>[i]</sup>（逼近值）的值，使用双边差分，将θ分为(θ<sub>1</sub>,θ<sub>2</sub>,......,θ<sub>i</sub>),然后求其偏导数，然后使用for循环对其每一个都求偏导。

​	**θ分为(θ<sub>1</sub>,θ<sub>2</sub>,......,θ<sub>i</sub>)的实际例子：**我们有一个权重向量 ( $\theta$ )，它包含了所有的权重参数 ( $\theta_1, \theta_2, \ldots, \theta_n$ )。如果我们有一个特征向量 ( x ) 和对应的权重向量 ($ \theta $)，那么模型的预测 ( $\hat{y} $) 可以通过向量内积来计算：
$$
\hat{y} = \theta^T x = \sum_{j=1}^{n} \theta_j x_j
$$
​	在执行梯度检验时，我们通常会计算两个向量之间的距离，即梯度的逼近值 ($ d\theta_{approx} $) 和实际的梯度 ( $d\theta $)。这个距离可以通过计算两个向量的欧几里得范数来得到，然后将其归一化，以便比较不同规模的参数。具体来说，我们计算的是：
$$
\frac{||d\theta_{approx} - d\theta||_2}{||d\theta_{approx}||_2 + ||d\theta||_2}
$$
​	这个比率被称为相对误差。当相对误差非常小，比如小于 ( $10^{-7} $)，这通常意味着梯度的逼近非常接近实际的梯度，表明梯度计算是正确的。如果相对误差在 ( $10^{-5}$ ) 到 ( $10^{-4}$ ) 之间，可能还可以接受，但需要谨慎；如果相对误差大于 ($10^{-3}$ )，则很可能计算中存在错误。

![image-20240609121210716](images/image-20240609121210716.png)

## 注意事项

1. **不要在训练就使用梯度检验，其仅适用于调试：** 梯度检验是计算密集型的，因为它需要对每个参数进行至少两次前向传播（对于双边差分）。如果在每次训练迭代中都进行梯度检验，将大大增加训练时间。因此，梯度检验通常仅在调试阶段使用，以验证梯度计算的正确性。

2. **梯度检验失败时的调试方法**：在梯度检验中，如果发现 ($d\theta_{approx}^{[i]}$ ) 与 ( $d\theta$ ) 之间的差异很大，这通常意味着在计算梯度时可能存在错误。这种情况下，我们需要逐个检查每个参数的梯度，以确定问题的具体位置。

   - 当我们发现某些层的 ( $db^{[L]}$ ) 的梯度检验失败（即 ( $d\theta_{approx}^{[i]}$ ) 与 ($ d\theta$ ) 差异很大），而相应层的 ( $dw^{[L]}$ ) 的梯度检验却通过了（即 ( $d\theta_{approx}^{[i]} $) 与 ($ d\theta$ ) 非常接近），这表明问题可能出在偏置参数 ( b ) 的梯度计算上。在神经网络中，权重 ( w ) 和偏置 ( b ) 是分开计算的，它们对应于不同的参数和梯度。如果 ( dw ) 的计算是正确的，但 ( db ) 的计算是错误的，那么这表明反向传播算法在计算偏置梯度时可能出现了问题。

     同样，如果某个特定的 ( $d\theta_{approx}^{[i]}$ ) 与 ( $d\theta$ ) 差异很大，而其他的梯度检验都通过了，那么这个特定的$ ( i ) $值可能指向了问题所在的参数。例如，如果这个$ ( i )$ 值对应于某一层的$dw$，那么问题可能出在这一层的权重梯度计算上。

3. **正则化项的影响**：在进行梯度检验的时候，如果使用正则化去除过拟合现象，请注意正则化项：即代价函数J<img src="images/image-20240609133439575.png" alt="image-20240609133439575" style="zoom: 67%;" />则计算dθ的时候要包括这个正则化的项。正则化项会影响梯度的值，如果在梯度检验中忽略了正则化项，将导致数值梯度与实际梯度不匹配。

4. **梯度检验与dropout的不兼容性**：Dropout是一种正则化技术，它通过随机丢弃网络中的一些单元来防止过拟合。由于dropout的随机性，每次迭代中丢弃的单元都不同，这使得梯度的计算变得不确定，难以计算dropout在梯度下降上的代价函数J。因此，在进行梯度检验时，应关闭dropout。

5. **梯度检验与参数初始化的关系**：参数初始化对于模型的训练和梯度检验都非常重要。参数 ( w )（权重）和 ( b )（偏置）的初始值会影响梯度下降算法的效率和梯度检验的准确性。当权重 ( w ) 和偏置 ( b ) 接近0时，意味着模型在开始训练时没有强烈的偏见，有助于模型更公平地探索权重空间，从而找到损失函数的全局最小值。其次，这种初始化方法有助于避免权重的对称性问题，即避免所有神经元都学习到相同的特征。

   然而，当 ( w ) 和 ( b ) 的值变大时，模型可能会进入激活函数的饱和区域，特别是当使用像Sigmoid或Tanh这样的激活函数时。在这些区域，激活函数的梯度非常小，这会导致梯度消失问题，使得梯度下降难以继续更新权重。此外，大的权重值也可能导致梯度爆炸，特别是在深层网络中，这会使得梯度下降无法稳定地收敛。

   在网络训练之前使用较小的随机值进行参数初始化，并进行梯度检验，是为了确保反向传播算法正确实施，梯度计算准确无误。这一步是在训练开始前的一个重要的验证步骤，因为此时参数还没有经过任何训练，数值稳定性问题较小。随着训练的进行，参数 ( w ) 和 ( b ) 会更新并远离初始值。如果在训练过程中进行梯度检验，由于参数值的增大，可能会遇到数值稳定性问题，导致梯度检验不再准确。此外，训练过程中引入的如动量、自适应学习率等优化技术，也会影响梯度的计算，使得梯度检验的结果不再可靠。因此，梯度检验通常在训练开始前进行，以验证梯度计算的正确性。一旦开始训练，就应该依赖于其他方法（如监控训练/验证损失）来确保模型的学习过程是正确的。

# Mini-batch梯度下降算法

​	前方我们已经经历过将数据集等进行矩阵化，但当数量庞大时，例如样本数为上百万千万，则运行速度依旧很慢。

​	在对整个训练集执行梯度下降法的时候，必须先处理整个训练集，然后才可以进行下一步梯度下降算法，然后你需要再重新处理百万个训练样本，才能进行下一步梯度下降算法。有一种更快的算法既是整个百万个样本的训练集之前，先让梯度下降算法处理一部分，则算法速度会更快。

1.把训练集分割为小一点的子训练集，这些子集被取名Mini-batch，假设每一个子集中有1000个样本，即x<sup>(1)</sup>和x<sup>(1000)</sup>取出来,将其称为第一个子训练集，x<sup>(1)</sup>和x<sup>(1000)</sup>把这个叫做x<sup>{1}</sup>,以此类推，假设共有5000个$Mini-batch$，则总数就为500万个。

2.对$Y$做相同的处理，

3.Mini-batch的数量t组成了x<sup>{t}</sup>和y<sup>{t}</sup>输入输出对。

4.batch即是同时处理所有的数据集，Mini-batch既是单个的Mini-batch的x<sup>{t}</sup>和y<sup>{t}</sup>输入输出对。

![image-20240621004423844](images/image-20240621004423844.png)

​	下图是进行$Mini-batch$的伪代码，简单来说就是一次处理1000个数据，以x<sup>{t}</sup>和y<sup>{t}</sup>为单位，其好处是一次遍历就下降了5000次梯度算法。

![image-20240621005014546](images/image-20240621005014546.png)

1. **Mini-batch 梯度下降法**：
   - 在传统的梯度下降法中，需要在每一次迭代中计算整个训练集的梯度，然后更新模型参数。但是，当训练集非常大时，这会变得非常耗时。
   - Mini-batch 梯度下降法通过将训练集分成小的子集（即 $Mini-batch$），每次只使用一个 $Mini-batch$ 来计算梯度和更新参数。这样，可以更频繁地更新模型，而不必等待整个训练集的处理。
2. **Mini-batch 的好处**：
   - **加速收敛**：$Mini-batch$ 允许更频繁地更新模型参数，从而加速收敛。相比于使用整个训练集的梯度，$Mini-batch$ 可以更快地找到局部最优解。
   - **减少内存需求**：使用整个训练集的梯度需要大量内存，而 $Mini-batch$ 只需要存储一个小的子集，因此内存需求更低。
   - **降低计算复杂度**：计算 Mini-batch 的梯度比整个训练集更快，因为它只涉及部分数据。
3. **选择 Mini-batch 大小**：
   - Mini-batch 的大小是一个超参数，需要根据具体问题进行调整。通常，较小的 $Mini-batch$ 可以更频繁地更新模型，但也会增加噪声。较大的 $Mini-batch$ 可以减少噪声，但更新频率较低。
   - 常见的 Mini-batch 大小包括 32、64、128 等。

## 5.1-理解Mini-batch 梯度下降法

​	对于其迭代-成本函数关系图，因为$Mini-batch$每次都在训练不同的样本，因此其总体呈下降趋势但噪音较多，产生噪音的原因在于也许x<sup>{1}</sup>和y<sup>{1}</sup>是比较容易计算的$Mini-batch$，因此成本会低一点；而x<sup>{2}</sup>和y<sup>{2}</sup>是比较难九三的Mini-batch这样成本会高一点，因此才会出现波动。

![image-20240621010529196](images/image-20240621010529196.png)

1. **Mini-batch 梯度下降法**：
   - Mini-batch 梯度下降法将训练集分成小的子集（Mini-batch），每次只使用一个 Mini-batch 来计算梯度和更新参数。
   - 这样做的好处是既能加速收敛，又能减少内存需求，但也引入了一些噪音。
2. **噪音的原因**：
   - Mini-batch 的大小是一个超参数，通常比整个训练集小得多。因此，每个 Mini-batch 只包含一部分样本，而不是全部。
   - 噪音主要来自于 Mini-batch 中样本的随机性。不同 Mini-batch 中的样本可能具有不同的特性，导致梯度的估计有一定的波动。
3. **成本函数图的特点**：
   - 成本函数图在 Mini-batch 梯度下降法中呈现出波动的特点，因为每个 Mini-batch 的样本不同，导致每次计算的成本函数值也不同。
   - 总体趋势是下降的，但由于噪音，成本函数图会有一些起伏。
4. **随机梯度下降法**：
   - 当 Mini-batch 的大小为 1 时，我们得到了随机梯度下降法。
   - 随机梯度下降法每次只使用一个样本来计算梯度，因此成本函数图会更加嘈杂，不会收敛到最小值，而是在最小值附近波动。
   - 这种方法的效率较低，因为它失去了向量化带来的好处。

![image-20240621011406101](images/image-20240621011406101.png)

# 指数加权平均

​	又名指数加权移动平均，下图为温度的散点图，如果计算温度的局部平均值（移动平均值）步骤如下。

​	**指数加权移动平均（EMA）的公式**：

- 假设第i天的温度为$θ_i$，我们要计算第$i$天的EMA。

- 初始值：$V_0 = 0$（通常设置为0，但也可以根据实际情况选择其他初始值）。

- EMA的计算公式：
  $$
  V_i = \beta V_{i-1} + (1 - \beta) \theta_i
  $$
  

  其中，$β$是权重系数，通常取0.9或0.98。

  ![image-20240621014439569](images/image-20240621014439569.png)

![image-20240621012151127](images/image-20240621012151127.png)

​	其计算结果近似等于图片中公式，也即多少天温度。

​	平均更多的值，指数加权平均公式在温度变化时，适应地更缓慢一些，所以会出现一定的延迟，当$β=0.98$，相当于给前一天值加了太多权重，只有0.02的权重给了当日的值，所以温度变化时，温度上下起伏，当$β$较大时，指数加权平均值适应地更慢一些。

**权重系数 β 的作用**：

- β 控制了历史数据的权重。较大的 β 会使EMA更加平滑，适应变化较慢，而较小的 β 会使EMA更加敏感，更快地适应变化。
- 当 β 接近1时，EMA对历史数据的依赖性较高，因此变化较慢。例如，当 β=0.98 时，只有0.02的权重给了当日的值，前一天的值占据了很大的权重。
- 当 β 较小（例如，β=0.5）时，EMA更快地适应温度变化，因为它平均了较短时间内的数据。

**EMA的优点**：

- EMA对噪声和短期波动具有抑制作用，因此在趋势分析、股票价格预测、信号处理等领域中广泛应用。
- 它能够平滑数据，减少随机波动，使趋势更明显。

![image-20240621012930191](images/image-20240621012930191.png)

## 6.1-理解指数加权平均

​	所谓加权平均，以$V_{100}$为例子，当$β=0.90$的时候，在0.9的10次方后，其值大约等于$\frac{1}{e}$,也即大约平均了从100往前的十天数据，这个天数计算就以$\frac{1}{1-β}$来算，所以当$β=0.98$，在0.98的50次方后其值大约等于$\frac{1}{e}$。

![image-20240621014321766](images/image-20240621014321766.png)

**指数加权平均的衰减因子**：

- $β $决定了EMA对历史数据的依赖程度。较大的$ β $会使EMA更加平滑，适应变化较慢，而较小的 $β$ 会使EMA更加敏感，更快地适应变化。
- 当$ β $接近1时，EMA对历史数据的权重较高，因此变化较慢。我们可以将$ \frac{1}{1−β}$ 视为EMA的衰减因子，表示EMA对历史数据的衰减速度。

## 6.2-指数加权平均的偏差修正

​	偏差修正可以让平均数运算的更加准确、当$β=0.98$时候，偏差修正使得曲线不再为绿而是紫色，右边既是偏差修正，随着天数t的增加，分母趋近于1，即不再有修正作用，这就是为什么后半部分会重合。

​	在EMA的计算中，如果不进行偏差修正，初始的平均值会受到初始值设为0的影响，导致计算结果偏小。这是因为EMA是通过递归地将当前值与过去的平均值结合来计算的，而在开始时，由于没有足够的历史数据，EMA会倾向于低估真实的平均值。

![image-20240621015254891](images/image-20240621015254891.png)

**偏差修正的作用**：

- 偏差修正的目标是消除初始数据对EMA的影响，使得EMA更准确地反映历史数据的平均趋势。

- 偏差修正的公式为：
  $$
  \hat{V}_i = \frac{V_i}{1 - \beta^i}
  $$
  

  其中，$V^i$ 是经过偏差修正后的EMA值。

- 注意，分母中的$1−β^i$是一个递增的因子，随着天数$i$的增加而逐渐接近1。

**偏差修正的效果**：

- 当$ i $较小时，分母接近1，偏差修正的效果较小。
- 随着$ i $的增加，分母逐渐减小，偏差修正的作用逐渐显现。
- 当$ i$ 较大时，分母接近1，偏差修正不再起作用，此时的EMA值与未修正的EMA值相同。

**为什么后半部分会重合**：

- 当$ i $较大时，偏差修正的效果逐渐减小，EMA值趋于稳定。
- 因此，后半部分的EMA曲线与未修正的EMA曲线重合，不再有明显的差异。

# 动量(Momentum)梯度下降法

​	基本想法为计算梯度的指数加权平均数，并利用该梯度更新你的权重，下图中在靠近最小值的时候，上下的波动减慢了梯度下降算法的速度，无法使用更大的学习率，如果使用更大的学习率，结果可能会偏离函数的范围，如紫线所示。

​	因此我们想要在纵轴上学习慢一点以减缓波动的产生，而加速横轴的学习速度.

​	Momentum梯度下降法即在第t次迭代中，计算$batch或者mini-batch$微分$dw,db$，利用此来计算$dw,db$，计算公式如下。
$$
V_{dW}=β*V_{dW}+(1-β)*dW
$$

$$
V_{db}=β*V_{db}+(1-β)*db
$$

$$
W=W-α*V_{dW};b=b-α*V_{db}
$$

​	因为纵轴是上下摆动，因此指数加权平均会使得平均值近似为0，而纵轴总体向一个方向，速度会更快。

![image-20240621021015289](images/image-20240621021015289.png)

​	通常β的值为0.9具有鲁棒性，$v_{dW},v_{db}$通常初始化为0。

![image-20240621021243088](images/image-20240621021243088.png)

# RMSProp

​	RMSProp算法是一种自适应学习率的优化算法，主要用于深度学习中的参数更新。它的目的是解决Adagrad算法在训练过程中学习率逐渐减小直至无法进一步学习的问题。RMSProp通过引入衰减系数β来解决这个问题，使得历史信息能够指数级衰减，从而避免了学习率持续下降的问题。	

​	与动量梯度算法目标一致，使得纵轴速度减缓，横轴速度增加，在第t次迭代中，算法会照常计算$batch或者mini-batch$微分$dw,db$，并利用以下公式计算。![image-20240621022553580](images/image-20240621022553580.png)
$$
S_{dW}=β*S_{dW}+(1-β)*(dW)^2
$$

$$
S_{db}=β*S_{db}+(1-β)*(db)^2
$$

$$
W=W-α*\frac{V_{dW}}{\sqrt{S_{dW}+ε}};b=b-α*\frac{V_{db}}{\sqrt{S_{db}+ε}}
$$

​	公式中的平方项$(dW)^2$和$(db)^2$确保了更新量与梯度的大小成正比，如果梯度很大，那么更新量也会相应增大，反之亦然。这有助于在纵轴上（通常对应于损失函数的斜率较大的方向）减少更新步长，以减少抖动，同时在横轴上（对应于斜率较小的方向）增加更新步长，以加快收敛速度。

​	在纵轴上斜率较大，因此$S_{db}$大，也即$b$方向会小，减少抖动，因为$S_{db}$出现在分母中，当$S_{db}$增大时，分母$\sqrt{S_{db}+ε}$也会增大，导致整个分数变小。这意味着b的更新量会减少，从而减少在b方向上的参数更新幅度。

​	横轴反之亦然。为了避免分母为0，通常会改写为$S_{dW}+ε，ε通常取10^{-8}$。

![image-20240621025213839](images/image-20240621025213839.png)

​	此时可以使用较大的学习率。

# Adam优化算法

​	Adam（Adaptive Moment Estimation）算法是一种高效的梯度下降优化方法，它确实结合了Momentum和RMSProp算法的优点。下面解释为什么Adam算法能够在训练的不同阶段调整学习率，并且如何影响模型的收敛性。

​	Adam算法通过动态调整学习率，结合了快速收敛和稳定到达最优解的优点。结合了动量方法和RMSProp算法的优点。Adam算法的核心原理是计算梯度的一阶矩（即均值）和二阶矩（即未中心化的方差）的指数加权平均，并使用这些矩来调整每个参数的学习率。

​	首先初始化，$V_{dW}=0,S_{dW}=0,V_{dB}=0,S{dB}=0$,在第t次迭代中，算法会照常计算$batch或者mini-batch$微分$dw,db$，并利用以下公式计算。
$$
V_{dW}=β_1*V_{dW}+(1-β_1)*dW,V_{db}=β_1*V_{db}+(1-β_1)*db
$$

$$
S_{dW}=β_2*S_{dW}+(1-β_2)*(dW)^2,S_{db}=β_2*S_{db}+(1-β_2)*(db)^2
$$

$$
{{V}_{dw}}^{corrlected} = \frac{V_{dw}}{1 - \beta^t_1},{{V}_{db}}^{corrlected} = \frac{V_{db}}{1 - \beta^t_1}
$$

$$
{{S}_{dw}}^{corrlected} = \frac{S_{dw}}{1 - \beta^t_2},{{S}_{db}}^{corrlected} = \frac{S_{db}}{1 - \beta^t_2}
$$

$$
W=W-α*\frac{{V_{dW}}^{collected}}{\sqrt{S_{dW}+ε}},b=b-α*\frac{{V_{db}}^{collected}}{\sqrt{S_{db}+ε}}
$$

​	β1和β2是两个不同的超参数，分别控制第一矩估计（即动量）和第二矩估计（即梯度的未中心化方差）的指数加权平均（EWA）的衰减率。

**β1控制第一矩估计（动量）:**

​	β1通常设置为一个较大的值（如0.9），这意味着动量会考虑较长的过去梯度序列。这有助于平滑梯度的波动，提供稳定的下降方向，从而加速收敛并减少震荡。

**β2控制第二矩估计（梯度的平方）:**

​	β2通常设置为一个更接近1的值（如0.999），这样可以保证算法在计算每个参数的自适应学习率时，能够充分考虑历史梯度的变化。这有助于算法在面对不同参数的不同梯度规模时，能够做出更细致的调整。

​	区分β1和β2允许算法在动量和自适应学习率之间进行独立的调整。如果使用相同的衰减率，可能会导致算法在调整动量和自适应学习率时不够灵活，从而影响性能。通过为这两个不同的目的设置不同的衰减率，Adam算法能够更好地适应各种不同的优化场景。

![image-20240621024706261](images/image-20240621024706261.png)

推荐数值![image-20240621024639409](images/image-20240621024639409.png)

# 学习率衰减

## 10.1-为什么要使用学习率衰减

​	假设使用$Mini-batch$，那么学习过程中的噪声，以及最后的结果将会是在目标点处振荡、并不会真正收敛（蓝色）；

​	在训练初期，较大的学习率 ( \alpha ) 可以帮助模型快速下降，避免陷入局部最小值。但是，当模型接近最优解时，较大的学习率可能会导致模型在最优解附近震荡，无法精确收敛。通过逐渐减小学习率，因此可以在训练后期减少步长，从而使模型更加稳定地收敛到最优解。

​	所以慢慢减小$α$的本质在于在学习初期可以承受较大的步伐、但在开始收敛的时候，小一些的学习率能让你步伐小一些、这样可以做到学习率衰减。

![image-20240625233456004](images/image-20240625233456004.png)

​	一次遍历叫做一代、如$Mini-batch$第一次遍历全部就是一代、第二次二代、以此类推。其中decay-rate叫做衰减率，一次一次会衰减，下图有误、学习率应该呈现下降趋势。

![image-20240625233912202](images/image-20240625233912202.png)

## 10.2-指数衰减

​	以及还有一些指数衰减等公式如下图所示。

![image-20240625234551705](images/image-20240625234551705.png)

# 局部最优问题

​	碰到的局部最优问题，在超多维空间中，通常不是局部最优点而是鞍点。

​	**鞍点** 是指在某些维度上，成本函数表现为局部最小值，而在其他维度上则是局部最大值。在高维空间中，由于维度的增加，鞍点的数量远远超过局部最优点。在鞍点附近，梯度接近于零，但是这并不意味着找到了一个好的解，因为在某些方向上仍然可以下降。

![image-20240625235750387](images/image-20240625235750387.png)

​	**平稳段** 是指成本函数在一个较大区域内变化不大，导数长时间接近于0。在这些区域，传统的梯度下降算法会变得非常缓慢，因为它们依赖于梯度信息来更新参数。

​	首先，我们不太可能会困在极差的局部最优中，条件是你在训练较大的神经网络，存在大量参数，且成本函数$J$被定义在较高维的空间中。在高维空间中，局部最优点确实不像在低维空间中那样常见。相反，鞍点（saddle points）和平坦区域（plateaus）更为普遍。这些区域的特点是，成本函数 ( J ) 的梯度接近于零，这会导致基于梯度的优化算法在这些区域停滞不前，从而减缓学习速度。

​	第二点，平稳段是一个问题，这会使得学习十分缓慢，类似Momentum或是RMSPROP能够加速学习的地方。而Adam可以让我们更快的走出平稳段。

![image-20240626000150948](images/image-20240626000150948.png)

​	为了解决这些问题，$Momentum $和 $RMSProp$ 等算法被提出。$Momentum$ 方法通过累积过去梯度的移动平均来加速学习，这有助于跳出局部最小值和鞍点。$RMSProp$ 通过调整每个参数的学习率来解决$AdaGrad$(全称$Adaptive Gradient$,又叫自适应梯度算法)在学习率递减过快时的问题。

​	$Adam$ 算法结合了 $Momentum$ 和 $RMSProp$ 的优点。它保持了梯度的一阶矩（均值）和二阶矩（未中心化的方差），有助于调整学习率，使其适应每个参数的特性。在平稳段，由于累积了过去梯度的信息，$Adam$ 能够保持一定的更新幅度，即使当前梯度很小或接近于零。$Adam$ 对梯度的二阶矩估计提供了一个自适应的学习率，这有助于调整每个参数的更新步长，从而更快地走出平稳段。

# 调试处理

吴恩达认为的超参数重要性如下图所示。<img src="images/image-20240628112902953.png" alt="image-20240628112902953" style="zoom: 50%;" />随机取点和精细搜索。这种方法的目的是在高维超参数空间中找到最优的超参数组合，以提高模型的性能。在相应维度下随机取点，然后看哪个效果更好。<img src="images/image-20240628113238506.png" alt="image-20240628113238506" style="zoom: 33%;" />精细搜索，在随机取点中找到效果最好的点，并放大周围区域然后再进行随机取点找到最好的点。<img src="images/image-20240628113435355.png" alt="image-20240628113435355" style="zoom: 33%;" />

1. **随机取点**:
   - 与网格搜索（每个超参数都尝试固定间隔的值）相比，随机取点允许在超参数空间中探索更多的组合，因为它不受限于固定的网格。
   - 随机取点可以更有效地探索超参数空间，因为一些超参数可能比其他超参数对模型性能的影响更大。通过随机采样，有更大的机会发现这些关键超参数的有效值。

1. **从粗略到细致**:
   - 一旦通过随机取点找到了一个表现良好的超参数组合，可以在该点周围的区域进行更密集的搜索。意味着在这个区域内进行更细致的随机取点，以找到可能的最优解。

## 12.1-超参数的合适范围

​	对于一个给定的$n^{[l]}$的取值范围是(50,100)。那么可以在其范围内随机取点，对于这种类似的我们可以这样做，但是对于一些特定的情况就不可以比如下图在(0.0001,1)之间取值，那么在(0.1,1)之间的概率有90%，这显然是不公平的，因此我们需要取对数再平均变为($10^{-4}$,$10^0$)，所以我们要做的就是在(-4,0)中，随机均匀的取值。

![image-20240628115040598](images/image-20240628115040598.png)

​	对于给定$β$的取值用于计算指数的加权平均值，加入$β$取值范围为(0.9,0.999),当计算指数的加权平均值时，0.9就好像在10个值中计算平均值，而0.999则为1000个值计算平均值。因此无法使用线性随机取值，那么考虑这个问题的最好方法是探究$1-β$，取值范围为(0.1,0.001)，所以应用上述方法即可。

​	值得一提的是当$β$取值范围为(0.9.0.9005)和(0.999,0.9995)这两个范围时，对系统的影响是截然不同的 ，前者是大概十个值计算平均而后者从1000个值到2000个值计算平均。

​	不同类型的超参数需要不同的采样策略。对于线性范围的超参数，可以直接进行均匀采样；而对于具有指数效应的超参数，应该在对数尺度上进行采样，以确保每个数量级的值都有相同的被选中概率。

![image-20240628120150843](images/image-20240628120150843.png)

## 12.2-Batch归一化(norm)

​	Batch归一化，对于前方我们所学到的将输入数据标准化，使其变得更易于处理<img src="images/image-20240628123616598.png" alt="image-20240628123616598" style="zoom:33%;" />那么我们也就可以将不同层的激活后的数据也进行标准化，使得下一层更容易，在实验中经常对$Z^{[L]}$做归一化。

​	因此我们需要的步骤就是使得其均值为0，方差为1的标准化，但我们又不想要使得所有的都是(0,1)标准化，因此代入超参数$γ,β$来调整其相对于(0,1)的偏移。
$$
\mu = \frac{1}{m} \sum_{i=1}^{m} z^{(i)}
$$

$$
\sigma^2 = \frac{1}{m} \sum_{i=1}^{m} (z^{(i)} - \mu)^2
$$

$$
{x}_{norm}^{(i)} = \frac{z^{(i)} - \mu}{\sqrt{\sigma^2 + \epsilon}}
$$

$$
\widetilde{z}^{(i)} = \gamma {x}_{norm}^{(i)} + \beta
$$



![image-20240628124527687](images/image-20240628124527687.png)

## 12.3-Batch Norm的实现

​	下面是计算步骤，而$γ和β$也可应用各种来进行优化，即在前向传播和反向传播中引进了两个新的超参数，因此可以使用梯度下降算法等，如Adam算法等都可以应用，简单来说就是用$\widetilde{z}^{(i)}$代替了${z}^{(i)}$。

![image-20240628130549780](images/image-20240628130549780.png)

​	事件中Batch归一化通常和Mini-batch应用。又因为是在标准化，因此后方的常数$b$我们可以去掉。

![image-20240628131322838](images/image-20240628131322838.png)

​	伪代码如下。

![image-20240628131446993](images/image-20240628131446993.png)

## 12.4-Batch Norm理解

​	Batch Normalization (BN) 是一种在训练深度神经网络时用来提高稳定性和性能的技术。通过对每层的输入进行标准化处理，有助于减少所谓的内部协变量偏移（Internal Covariate Shift）。这个术语描述了训练过程中，网络各层输入数据分布的变化，这种变化会导致学习过程变得复杂和缓慢，因此BN可以使权重比网络更滞后或更深层，比如第十层的权重更能经得起变化。。

​	使得数据改变分布(covariate shift)，各个层的$W,b$都会改变从而影响到后面的，使得每层学习起来会更加不确定，困难，而Batch Norm使得方差和均值稳定在一定范围内，从而限制了这种变化，使得其更加稳定，利于学习。

1. **减少内部协变量偏移**：在没有BN的情况下，每层的输入分布随着前面层权重的更新而变化。这意味着，深层网络中的层必须不断适应这些变化，从而使得权重更新变得困难。BN通过标准化每层的输入，使得每层的输入分布更加稳定，减少了这种变化。
2. **加速学习过程**：由于输入分布的稳定性，可以使用更大的学习率，而不会导致梯度消失或爆炸。这使得权重更新更加有效，加速了学习过程。
3. **减少对初始化的依赖**：BN减少了模型对权重初始化的敏感性。即使深层的权重初始化不理想，BN也能够通过调整其标准化参数来适应，从而使权重更能经得起变化。
4. **提供一定的正则化效果**：BN在每个小批量上计算均值和方差，引入了一些噪声。这种噪声可以看作是一种正则化，有助于防止模型过拟合，提高泛化能力。
5. **保持非线性特性**：BN通过引入可学习的缩放和偏移参数（γ和β），允许模型恢复激活函数的非线性特性。这意味着即使在标准化后，模型也能够学习到数据中的复杂模式（相当于对$z^{[L]}$的均值和方差的偏移，使得进入激活函数的非线性区）。

![image-20240628134443807](images/image-20240628134443807.png)

​	再者，BN具有轻微的正则化效果，因为在每个小批量中加入了噪声，这有助于模型泛化。

​	Batch归一化（Batch Normalization，简称BN）主要是因为它在每个小批量（mini-batch）的数据处理中引入了一些噪声，因此$batch_{size}$越大，噪声越小，正则化效果越弱，而BN也正是利用这些来标准化，因此含有轻微正则化效果，这里的“噪声”并不是传统意义上的随机噪声，而是由于在每个小批量中计算得到的均值和方差带有随机性，因为它们依赖于当前批量中的样本。

## 12.5-Batch Norm测试实现

​	在归一化过程中，$μ和\sigma^2$是在整个mini-batch上计算的，但是在测试中，不可能将一个mini-batch中的多个样本同时处理，因此我们需要是用其他方法来得到$μ和\sigma^2$，且一个样本的均值和方差没有意义，我们使用训练时计算的指数加权平均来估算，这个平均数覆盖了所有mini-batch。

​	在训练阶段，Batch Normalization (BN) 通过对每个mini-batch的数据计算均值($μ$)和方差($\sigma^2$)来进行归一化，我们通常有足够多的数据来构成一个mini-batch；然而，测试时，我们可能需要对单个样本或者比训练时小得多的batch进行预测。在这种情况下，如果我们仍然试图计算每个mini-batch的$μ和\sigma^2$，会遇到以下问题：

​	1.**样本数量不足：**一个样本的均值和方差没有统计意义，因为它们不能代表整个数据集的分布。

​	2.**不一致的数据分布：**即使我们有一个小的batch，它的统计特性也可能与训练时使用的mini-batches不同，这可能导致预测结果的不稳定。

​	因此在测试时使用训练阶段计算的指数加权平均值来估算$μ和\sigma^2$。这些值是在整个训练过程中累积的，可以看作是对整个训练数据集统计特性的一个估计。

这种方法的优点是：

- **稳定性**：使用全局的统计值可以保证测试时的归一化处理与训练时相一致，从而提高模型的泛化能力。
- **效率**：全局的统计值只需要计算一次，可以在测试时直接使用，无需针对每个小的batch重新计算。
- **一致性**：这确保了模型在训练和测试阶段看到的数据分布是一致的，减少了由于数据分布不同导致的性能波动。

![image-20240628140106446](images/image-20240628140106446.png)
