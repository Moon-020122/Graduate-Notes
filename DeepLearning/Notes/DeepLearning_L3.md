# ML策略

​	机器学习（ML）策略是指在开发和优化机器学习模型时所采用的一系列方法和步骤，以确保模型能够高效、准确地完成任务。

## 1.1-正交化

​	正交化简单来说就是确保改变一个参数的时候只改变一个你想要调整的东西；例如汽车的速度控制和转向，如果有一个按钮同时控制速度和转向，那么就很难达到想要的效果，正交化就是两个旋钮分别控制速度和转向，那么就很容易得到自己想要的效果。

​	正交化可以独立地调整模型的不同方面，从而更有效地优化模型性能。

![image-20240704130041516](images/image-20240704130041516.png)

​	好的一个监督学习系统，需要确保四点

- **系统至少在训练集上得到的结果不错**：
  - **按钮**：切换优化算法或训练更大的网络。
  - **原因**：在训练集上表现良好意味着模型能够很好地拟合训练数据。通过切换优化算法（如从SGD切换到Adam）或训练更大的网络（增加层数或神经元数量），可以提高模型的表达能力和训练效率，从而在训练集上获得更好的结果。

- **在验证集上得到的结果不错**：

  - **按钮**：调整正则化。

  - **原因**：验证集用于评估模型的泛化能力。如果模型在验证集上表现不佳，可能是过拟合或欠拟合的问题。通过调整正则化（如L2正则化、Dropout），可以控制模型的复杂度，防止过拟合，从而在验证集上获得更好的结果。

- **在测试集上得到的结果不错**：

  - **按钮**：需要更大的开发集。

  - **原因**：测试集用于最终评估模型的性能。如果模型在测试集上表现不佳，可能是因为开发集（训练集和验证集）的数据分布与测试集不一致。通过增加开发集的规模和多样性，可以更好地代表测试集的数据分布，从而提高模型在测试集上的表现。

- **在实际应用中结果不错**：

  - **按钮**：改变验证集或成本函数J。

  - **原因**：实际应用中的表现是最终目标。如果模型在实际应用中表现不佳，可能是因为验证集与实际应用场景不匹配，或者成本函数J没有正确反映实际应用中的需求。通过调整验证集使其更接近实际应用场景，或重新定义成本函数J以更好地反映实际需求，可以提高模型在实际应用中的表现。

![image-20240704145128042](images/image-20240704145128042.png)

## 1.2-单实数评估指标

​	如果存在一个单实数评估指标，其可以告诉我们新尝试的方法比之前的方法好还是坏，因此我们需要为问题设置一个单实数评估指标。

- **查准率（Precision）**：表示在所有被模型预测为正类（例如猫）的样本中，实际为正类的比例。公式为：
  $$
  \text{Precision} = \frac{\text{True Positives}}{\text{True Positives} + \text{False Positives}}
  $$

- **查全率（Recall）**：表示在所有实际为正类（例如猫）的样本中，被模型正确识别为正类的比例。公式为：
  $$
  \text{Recall} = \frac{\text{True Positives}}{\text{True Positives} + \text{False Negatives}}
  $$

​	现在的问题是如果在A和B中一个查准率高一个查全率高，那么就无法快速分辨哪个分类器更优，因此并不推荐使用两个评估指标，即查全率和查准率来选择一个分类器，我们需要找到一个新的评估指标能够结合查全率和查准率，即F1分数。

**F1分数**是一个非常有用的评估指标，特别是在查准率（Precision）和查全率（Recall）之间需要权衡的情况下。F1分数是查准率和查全率的调和平均数，其公式为：
$$
F1 = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
$$

### 调和平均数

调和平均数比算术平均数更适合用于衡量两个数值的平衡，特别是在两个数值差异较大时。以下是具体原因：

1. **平衡性**：F1分数通过调和平均数来平衡查准率和查全率。如果一个模型的查准率很高但查全率很低，或者反之亦然，F1分数会较低。这意味着F1分数只有在查准率和查全率都较高时才会较高，从而鼓励模型在这两个指标上都表现良好。
2. **惩罚极端值**：调和平均数对极端值（即一个值很高而另一个值很低）的惩罚更大。例如，如果查准率为1而查全率为0，F1分数将为0，而不是0.5。这种特性使得F1分数能够更好地反映模型在查准率和查全率上的综合表现。

![image-20240704150615533](images/image-20240704150615533.png)

## 1.3-满足和优化指标

​	假设我们设定在满足运行时间要求的情况下，要最大限度的提高准确的，则这就是一个满足和优化指标；其中运行时间=满足指标，准确率=优化指标。

## 1.4-训练、开发、测试集

​	机器学习中的工作流程是：用训练集训练不同的模型，然后使用开发集来评估不同的思路，然后选择一个不断迭代去改善开发集的性能直到最后可以得到一个令人满意的成本，然后再用测试集去评估。

1. **用训练集训练不同的模型**：
   - **目的**：训练集用于训练模型，调整模型的参数，使其能够学习数据中的模式和特征。
   - **过程**：选择不同的模型架构和算法，使用训练集进行训练，调整模型的权重和偏置。
2. **使用开发集评估不同的思路**：
   - **目的**：开发集（也称验证集）用于评估模型的性能，选择最优的模型和超参数。
   - **过程**：在训练过程中，不断使用开发集评估模型的性能，调整超参数（如学习率、正则化参数等），选择在开发集上表现最好的模型。
3. **选择一个模型并不断迭代优化**：
   - **目的**：通过不断迭代，优化模型在开发集上的性能，确保模型能够泛化到未见过的数据。
   - **过程**：根据开发集的反馈，调整模型架构、超参数和训练策略，直到在开发集上达到令人满意的性能。
4. **用测试集进行最终评估**：
   - **目的**：测试集用于最终评估模型的性能，确保模型在未见过的数据上也能表现良好。
   - **过程**：在模型优化完成后，使用测试集进行评估，计算模型的最终性能指标（如准确率、F1分数等）。

### 原因

1. **防止过拟合**：通过使用开发集评估模型，可以防止模型在训练集上过拟合。过拟合的模型在训练集上表现很好，但在新数据上表现不佳。
2. **选择最优模型**：开发集用于选择最优的模型和超参数，确保模型在不同的配置下都能表现良好。
3. **最终评估**：测试集用于最终评估模型的性能，确保模型在未见过的数据上也能表现良好。这是对模型泛化能力的最终检验。

### 如何选择开发集和验证集？

1. **数据划分比例**：
   - **传统方法**：在数据量较小时，通常将数据集划分为训练集、验证集和测试集，比例为6:2:2或7:2:1
   - **大数据方法**：在数据量较大时，验证集和测试集的比例可以较小，例如98:1:1
2. **随机抽样**：
   - 从训练集中均匀随机抽样一部分样本作为验证集]确保验证集和测试集的数据分布与训练集一致，以便模型能够在不同数据集上表现一致。
3. **数据代表性**：
   - 确保验证集和测试集具有代表性，能够反映实际应用中的数据分布]避免数据偏斜，确保不同类别的数据数量相对均衡。

选择可以反应在未来你所期望的开发集和测试集以及认为重要的数据和必须得到好结果的数据。

## 1.5-贝叶斯最优错误率

​	贝叶斯最优错误率一般认为是理论上最可能达到的最优错误率，代表了在已知数据分布情况下，数据所能提供的最大信息量。因此，它是理论上可以达到的最低错误率。

### 为什么人工智能在超越人类错误率后很难再增长？

1. **接近理论极限**：当人工智能系统的错误率接近贝叶斯最优错误率时，进一步降低错误率变得非常困难，因为已经接近数据和模型的理论极限
2. **数据和模型的局限性**：即使有大量的数据和复杂的模型，仍然存在一些不可避免的噪声和不确定性，这些因素限制了模型的进一步改进
3. **边际收益递减**：在错误率较高时，改进模型可以显著降低错误率，但当错误率已经很低时，进一步改进所带来的收益会逐渐减少
4. **人类水平的瓶颈**：许多任务中，人类水平已经非常接近贝叶斯最优错误率，因此人工智能在超越人类水平后，进一步提升的空间非常有限

## 1.6-可避免偏、方差

### 偏差和方差

偏差（Bias）和方差（Variance）是机器学习中评估模型性能的重要概念，它们描述了模型在训练数据和新数据上的表现。以下是它们的区别和在人工智能中的影响：

**偏差（Bias）**

- **定义**：偏差是指模型预测值与真实值之间的差异。高偏差意味着模型对训练数据的拟合程度不够，通常表现为欠拟合（Underfitting）。
- **影响**：高偏差的模型过于简单，无法捕捉数据中的复杂关系，导致在训练数据和新数据上都表现不佳。

方差（Variance）

- **定义**：方差是指模型在不同训练数据集上的预测结果的波动程度。高方差意味着模型对训练数据中的噪声和细节过于敏感，容易过拟合（Overfitting）。
- **影响**：高方差的模型在训练数据上表现很好，但在新数据上表现差，因为它学习到了训练数据中的噪声和不相关的细节。

![image-20240704191427891](images/image-20240704191427891.png)

### 减少方差和偏差

![image-20240704193205013](images/image-20240704193205013.png)

